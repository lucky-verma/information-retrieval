{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jldVX0iOG3jK"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/lucky-verma/information-retrieval/blob/main/ir_synthetic_data_rag_rerank_fine_tune.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# AWS Case Studies and Blogs Information Retrieval System\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project aims to develop an advanced information retrieval system specifically designed for AWS case studies and blogs. Our goal is to create a robust solution that can efficiently fetch the most relevant documents from a large corpus of AWS-related articles and generate accurate responses to user queries based on the retrieved context.\n",
        "\n",
        "Key components of this project include:\n",
        "\n",
        "1. Data Preparation: We use a curated dataset of AWS case studies and blogs, available on Kaggle (<https://www.kaggle.com/datasets/harshsinghal/aws-case-studies-and-blogs>). This dataset serves as the foundation for our information retrieval system.\n",
        "\n",
        "2. Embedding Generation: We utilize state-of-the-art sentence transformer models to generate high-quality embeddings for our document chunks, enabling efficient similarity search.\n",
        "\n",
        "3. Vector Storage: We implement ChromaDB for vector storage in our development environment, with considerations for scaling to pgvector in a production setting.\n",
        "\n",
        "4. Retrieval and Reranking: Our system employs a two-stage retrieval process, using initial similarity search followed by a cross-encoder model for reranking to improve result relevance.\n",
        "\n",
        "5. Synthetic QA Dataset Generation: To enhance our model's performance, we generate a synthetic question-answer dataset saved on Hugging Face (https://huggingface.co/datasets/thinkersloop/aws-case-studies-and-blogs-short) using advanced language models.\n",
        "\n",
        "6. Model Fine-Tuning: We fine-tune a LoRA adapter on the LLaMA 3 8B model (https://huggingface.co/thinkersloop/llama-3-8b-bnb-4bit) to specialize in AWS-related queries and responses.\n",
        "\n",
        "7. Evaluation: We implement a evaluation strategy to assess the performance of our information retrieval and question-answering system.\n",
        "\n",
        "\n",
        "This notebook walks through the entire process, from data preparation to model deployment, providing a comprehensive guide to building a sophisticated information retrieval and question-answering system for AWS-related content.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu7e8egAA1iR"
      },
      "source": [
        "# Setup and Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4149vEj_G3jM"
      },
      "source": [
        "##### Installing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3603XZTeG3jN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install tiktoken\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets\n",
        "!pip install py7zr\n",
        "!pip install chromadb\n",
        "!pip install sentence_transformers\n",
        "!pip install langchain_community\n",
        "!pip install gradio pydantic\n",
        "!pip install gradio\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWTzx9yoHHfa",
        "outputId": "ba1087f6-016c-4190-b345-2e999ebc2c9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "_CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15102MB, multi_processor_count=40)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# running on gpu\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "\n",
        "torch.cuda.get_device_properties(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6fMkcDLIxqC"
      },
      "source": [
        "##### Load Kaggle dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "jj4OEKypIxGg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Please add required keys in colab\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "\n",
        "!kaggle datasets download -d harshsinghal/aws-case-studies-and-blogs\n",
        "!mkdir data/\n",
        "!unzip \"aws-case-studies-and-blogs.zip\" -d data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZZmmE56zL_r4"
      },
      "outputs": [],
      "source": [
        "# dataset path\n",
        "dataset_path = './data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjCD59IzBZjA"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXYdx6OhPHS5"
      },
      "source": [
        "## Sentence Chunking and Document Processing\n",
        "My data preparation process focuses on efficient text processing and chunking:\n",
        "- Uses SpaCy for NLP tasks and custom sentence-based chunking\n",
        "- Cleans text and Assigns unique IDs and metadata (source, topic) to each chunk\n",
        "- Outputs LangChain-compatible Document objects\n",
        "\n",
        "This approach offers fine-grained control over the text processing pipeline, crucial for optimizing vector storage and retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uEONeMKm8Vn1"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import torch\n",
        "import uuid\n",
        "\n",
        "from typing import List, Dict\n",
        "from transformers import pipeline\n",
        "from langchain.schema import Document\n",
        "\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading en_core_web_sm model...\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    return ' '.join(token.text for token in nlp(text) if not token.is_space)\n",
        "\n",
        "def is_case_study(file_name: str) -> bool:\n",
        "    return \"case study\" in file_name.lower()\n",
        "\n",
        "def process_chunk(text: str, source: str, topic: str) -> Dict:\n",
        "    cleaned_text = clean_text(text)\n",
        "\n",
        "    metadata = {\n",
        "        \"source\": source,\n",
        "        \"topic\": topic\n",
        "    }\n",
        "    return {\n",
        "        \"id\": str(uuid.uuid4()),\n",
        "        \"text\": cleaned_text,\n",
        "        \"metadata\": metadata\n",
        "    }\n",
        "\n",
        "def process_file(file_path: str, chunk_size: int = 500, chunk_overlap: int = 100) -> List[Dict]:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Calculate the topic using the file name\n",
        "    # TODO: We can use Zero-shot classification, if we want more tags\n",
        "    file_name = os.path.basename(file_path)\n",
        "    is_case_study_file = is_case_study(file_name)\n",
        "    file_topic = \"case-study\" if is_case_study_file else \"blog\"\n",
        "\n",
        "    chunks = []\n",
        "    doc = nlp(content)\n",
        "    current_chunk = []\n",
        "    current_size = 0\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        sentence_size = len(sent.text)\n",
        "        if current_size + sentence_size > chunk_size and current_chunk:\n",
        "            chunks.append(process_chunk(\" \".join(current_chunk), file_path, file_topic))\n",
        "            overlap_size = 0\n",
        "            while overlap_size < chunk_overlap and current_chunk:\n",
        "                overlap_size += len(current_chunk[0])\n",
        "                current_chunk = current_chunk[1:]\n",
        "            current_size = sum(len(s) for s in current_chunk)\n",
        "        current_chunk.append(sent.text)\n",
        "        current_size += sentence_size\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(process_chunk(\" \".join(current_chunk), file_path, file_topic))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def process_folder(folder_path: str, chunk_size: int = 500, chunk_overlap: int = 100) -> List[Dict]:\n",
        "    all_documents = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith('.txt'):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            try:\n",
        "                documents = process_file(file_path, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "\n",
        "                # Create documents for each chunk\n",
        "                for doc in documents:\n",
        "                    all_documents.append(Document(page_content=doc['text'],\n",
        "                                                  metadata=doc['metadata']))\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {file_path}: {str(e)}\")\n",
        "\n",
        "    return all_documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pwqb5z8T8Vlb",
        "outputId": "bdb16cb4-0a3c-4d66-f8cf-20e7be9447a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded 16667 document chunks\n"
          ]
        }
      ],
      "source": [
        "# Process folder with txt files\n",
        "split_docs = process_folder(dataset_path)\n",
        "print(f\"\\nLoaded {len(split_docs)} document chunks\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6z_NTxldNZk",
        "outputId": "e935cbb4-ba07-4c8f-a10d-592d2997b346"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': './data/6sense Case Study.txt', 'topic': 'case-study'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_docs[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "AGy8jNCJdNXI",
        "outputId": "fc2e0d7f-c00c-48e2-ddd2-ce2def958bec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Searching for a more scalable solution , 6sense began to explore Kubernetes , an open - source container orchestration system , to improve its data pipelines . In 2018 , the company migrated its application and API services to two Kubernetes clusters and began using kOps , a set of tools for installing , operating , and deleting Kubernetes clusters in the cloud .'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_docs[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-DICqWTCfvh"
      },
      "source": [
        "# Embedding Generation & Vector Store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NG7qynSRRe3"
      },
      "source": [
        "## Generate embeddings using Sentence Transformers\n",
        "\n",
        "Now, let's use a pre-trained Sentence Transformer model to generate embeddings:\n",
        "\n",
        "The all-MiniLM-L6-v2 model is an excellent choice for sentence embeddings due to its balance of performance and efficiency. This model offers high-quality embeddings while being relatively small and fast, making it suitable for various applications. It performs well on semantic similarity tasks and can handle multiple languages, making it versatile for different use cases. The model's compact size also allows for easier deployment and reduced computational requirements, making it an attractive option for projects with resource constraints or those requiring quick processing times.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bASdTk9zRRQ-"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize all-MiniLM-L6-v2 model\n",
        "embed_model_name = \"all-MiniLM-L6-v2\"\n",
        "model_kwargs = {\"device\": \"cuda:0\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "embed_model = HuggingFaceEmbeddings(\n",
        "    model_name=embed_model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-5AKj_uRROk",
        "outputId": "b4c4891d-e2b2-40d6-9fb6-4a634f552885"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              "), model_name='all-MiniLM-L6-v2', cache_folder=None, model_kwargs={'device': 'cuda:0'}, encode_kwargs={'normalize_embeddings': True}, multi_process=False, show_progress=False)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embed_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_yeWlMzIeuK"
      },
      "source": [
        "## Fine-Tune Embedding Model on our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {
        "id": "MZ2wYGJSJTql"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import InputExample\n",
        "import random\n",
        "\n",
        "def create_training_examples(documents, pos_pairs_per_doc=5, neg_pairs_per_doc=5):\n",
        "    examples = []\n",
        "    all_sentences = []\n",
        "    doc_boundaries = [0]\n",
        "\n",
        "    # Pre-process all documents\n",
        "    for doc in documents:\n",
        "        sentences = doc.page_content.split('. ')\n",
        "        all_sentences.extend(sentences)\n",
        "        doc_boundaries.append(len(all_sentences))\n",
        "\n",
        "    all_sentences = np.array(all_sentences)\n",
        "\n",
        "    for i in range(len(documents)):\n",
        "        start, end = doc_boundaries[i], doc_boundaries[i+1]\n",
        "        doc_sentences = all_sentences[start:end]\n",
        "\n",
        "        # Positive pairs\n",
        "        if len(doc_sentences) > 1:\n",
        "            pos_pairs = np.random.choice(len(doc_sentences), size=(pos_pairs_per_doc, 2), replace=True)\n",
        "            for pair in pos_pairs:\n",
        "                examples.append(InputExample(texts=[doc_sentences[pair[0]], doc_sentences[pair[1]]], label=1.0))\n",
        "\n",
        "        # Negative pairs\n",
        "        for _ in range(neg_pairs_per_doc):\n",
        "            other_doc_idx = np.random.choice([j for j in range(len(documents)) if j != i])\n",
        "            other_start, other_end = doc_boundaries[other_doc_idx], doc_boundaries[other_doc_idx+1]\n",
        "            other_sentence = np.random.choice(all_sentences[other_start:other_end])\n",
        "            examples.append(InputExample(texts=[np.random.choice(doc_sentences), other_sentence], label=0.0))\n",
        "\n",
        "    return examples\n",
        "\n",
        "train_examples = create_training_examples(split_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703,
          "referenced_widgets": [
            "d070d8cf5f9842239649a9902f976db5",
            "d2c2a43c1ad84c82aac0b4e9a3490c73",
            "51c5557ee3b943139d23eaf3a4c394cd",
            "964f6a3e3a984bd29dbad2ae0dc32156",
            "331400eea2fc496e902950ee00a75155",
            "627ceca8795844c5b15eaa56fbb5b4a6",
            "4c2878f58a85493fab9e011d557a4f15",
            "2331c6d434d04cee932e2c514733e9a5",
            "47713a7eb44c4df88c59219f2bdd8ca5",
            "ec1f188ec1ab44818f1e6c88cf2bbe88",
            "53b118b63434456cb06b0224ac237a61"
          ]
        },
        "id": "sYUhusqaPkLE",
        "outputId": "13ead904-424d-4d6d-efff-c76ce0ea37b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10300' max='10300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10300/10300 14:29, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.138900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.151300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.132400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.121400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.096700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>2.058800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>2.086400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>2.083900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>2.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>2.034700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>2.058900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>2.045500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>2.063500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>2.020200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>2.035800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>2.036300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>2.028900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>2.006800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>2.021400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d070d8cf5f9842239649a9902f976db5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from torch.utils.data import DataLoader\n",
        "from sentence_transformers import losses\n",
        "\n",
        "# Initialize the embedding model for training\n",
        "base_embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "train_loss = losses.MultipleNegativesRankingLoss(base_embed_model)\n",
        "\n",
        "# Fine-tune the model\n",
        "base_embed_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=10)\n",
        "\n",
        "# Save the fine-tuned model\n",
        "base_embed_model.save('fine_tuned_aws_embeddings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4jqUU5fYKacl"
      },
      "outputs": [],
      "source": [
        "# load the embedding model\n",
        "original_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "fine_tuned_model = SentenceTransformer('fine_tuned_aws_embeddings')\n",
        "\n",
        "test_docs = split_docs[-100:]  # Use the last 100 documents as a test set\n",
        "test_queries = [\"What did 6Sense use for scaling?\", \"How Rivian uses AWS?\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KV0wv26IloW",
        "outputId": "9745325c-6c5f-467a-b379-4647f223a1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------------\n",
            "Original Model Retrieval:\n",
            "-----------------------------------------------------------------------------------\n",
            "Query: What did 6Sense use for scaling?\n",
            "Top 1 document (similarity: 0.2303): The team uses Service Workbench on AWS to ...\n",
            "Top 2 document (similarity: 0.2152): “ The ability to scale resources dynamical...\n",
            "Top 3 document (similarity: 0.2113): Using Optimizing for Efficiency and Innova...\n",
            "Top 4 document (similarity: 0.2113): Typically , these datasets are large and s...\n",
            "Top 5 document (similarity: 0.2001): Researchers can securely access large data...\n",
            "\n",
            "\n",
            "Query: How Rivian uses AWS?\n",
            "Top 1 document (similarity: 0.8009): It is designed to make web - scale cloud c...\n",
            "Top 2 document (similarity: 0.7966): Contact our experts and start your own AWS...\n",
            "Top 3 document (similarity: 0.7966): Rivian pushes the pace of automotive innov...\n",
            "Top 4 document (similarity: 0.7534): The company uses Using the Breadth of AWS ...\n",
            "Top 5 document (similarity: 0.7458): “ Changes that took 5 days now occur withi...\n",
            "\n",
            "\n",
            "-----------------------------------------------------------------------------------\n",
            "Fine-tuned Model Retrieval:\n",
            "-----------------------------------------------------------------------------------\n",
            "Query: What did 6Sense use for scaling?\n",
            "Top 1 document (similarity: 0.6462): Improves adaptability for collaborative re...\n",
            "Top 2 document (similarity: 0.6447): Rivian looked to the cloud to overcome thi...\n",
            "Top 3 document (similarity: 0.6446): Using SDO , researchers can explore import...\n",
            "Top 4 document (similarity: 0.6411): Get Started Beyond traditional use cases ,...\n",
            "Top 5 document (similarity: 0.6398): Using Optimizing for Efficiency and Innova...\n",
            "\n",
            "\n",
            "Query: How Rivian uses AWS?\n",
            "Top 1 document (similarity: 0.8968): It is designed to make web - scale cloud c...\n",
            "Top 2 document (similarity: 0.8931): Amazon Elastic Compute Cloud ( Amazon EC2 ...\n",
            "Top 3 document (similarity: 0.8867): CloudFormation , which enables users to sp...\n",
            "Top 4 document (similarity: 0.8851): The company uses Using the Breadth of AWS ...\n",
            "Top 5 document (similarity: 0.8785): Rivian plans to continue migrating workloa...\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def retrieve_documents(model, query, documents, top_k=5):\n",
        "    query_embedding = model.encode([query])[0]\n",
        "    doc_embeddings = model.encode([doc.page_content for doc in documents])\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    return [(documents[i], similarities[i]) for i in top_indices]\n",
        "\n",
        "def evaluate_retrieval(model, queries, documents):\n",
        "    for query in queries:\n",
        "        print(f\"Query: {query}\")\n",
        "        retrieved_docs = retrieve_documents(model, query, documents)\n",
        "        for i, (doc, similarity) in enumerate(retrieved_docs, 1):\n",
        "            print(f\"Top {i} document (similarity: {similarity:.4f}): {doc.page_content[:42]}...\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "print('-' * 83)\n",
        "print(\"Original Model Retrieval:\")\n",
        "print('-' * 83)\n",
        "evaluate_retrieval(original_model, test_queries, test_docs)\n",
        "print('-' * 83)\n",
        "print(\"Fine-tuned Model Retrieval:\")\n",
        "print('-' * 83)\n",
        "evaluate_retrieval(fine_tuned_model, test_queries, test_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxfKJeq-aHXA"
      },
      "source": [
        "You can see scores are better with Fine-Tune embedding model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXWLdCxsPQ7Z"
      },
      "source": [
        "## Set up Chroma and embed documents using `fine_tuned_model`\n",
        "\n",
        "I chose ChromaDB for my project because it's lightweight, easy to set up, and perfect for quick prototyping in my Jupyter notebook. It doesn't require a separate database server, which simplifies my development process.\n",
        "\n",
        "However, for a production environment with 4x A100 GPUs serving 1000 users daily, I'd opt for PostgreSQL with pgvector. It offers better scalability, concurrent access, and ACID compliance. PG Vector can handle larger datasets and more complex queries efficiently, which is crucial for high-performance production systems. Plus, it integrates well with existing PostgreSQL infrastructure, making it easier to manage and maintain in a production setting.\n",
        "\n",
        "Now, let's set up Chroma as our vector store and embed the documents:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "gyq5ZS_QatI2"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Initialize the fine tuned embedding model\n",
        "fine_tuned_embed_model = HuggingFaceEmbeddings(\n",
        "    model_name='fine_tuned_aws_embeddings',\n",
        "    model_kwargs={\"device\": \"cuda:0\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LyOCunYBO8yD"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Create a Chroma vector store\n",
        "db = Chroma.from_documents(\n",
        "    documents=split_docs,\n",
        "    embedding=fine_tuned_embed_model,\n",
        "    persist_directory=\"./db_chroma\"\n",
        ")\n",
        "\n",
        "# Persist the database\n",
        "db.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhxIPXtgC891"
      },
      "source": [
        "# Retrieval and Reranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBGpls17Lu-S"
      },
      "source": [
        "#### ReRanker using Cross Encoder model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du_45JhJAuMW",
        "outputId": "4acaa0bd-ae7e-4515-8529-1bcdc7b7a0b1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-mpnet-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers.cross_encoder import CrossEncoder\n",
        "\n",
        "# Initiating Cross-Encoder Model for reranking top documents\n",
        "cross_encoder_model = CrossEncoder('sentence-transformers/all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "LzvvgXuBAuKX"
      },
      "outputs": [],
      "source": [
        "# Method to find top Documents\n",
        "\n",
        "def find_top_docs(question, db_collection, cross_encoder_model, embed_model, top_k=4):\n",
        "\n",
        "    \"\"\"\n",
        "    Find the top-k documents matching the query and also send the most suitable\n",
        "    document after re-ranking depending on the input question.\n",
        "\n",
        "      Args:\n",
        "          question (str): The Question from user.\n",
        "          db_collection (collection): object with embeddings for all the text chunks.\n",
        "          cross_encoder_model (CrossEncoder): Model for reranking top documents found in initial search result.\n",
        "          embed_model(HuggingFaceBgeEmbeddings): Model for embedding all text chunks\n",
        "          top-k (int): Number of chunks most related to the query.\n",
        "\n",
        "      Returns:\n",
        "          str: most suitable document depending on the input question.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    qembed= embed_model.embed_query(question)\n",
        "    result = db_collection.similarity_search_with_score(question, k=top_k)\n",
        "\n",
        "    # Unpack the tuples and keep both document content and initial scores\n",
        "    top_docs_list = [(doc.page_content, score) for doc, score in result]\n",
        "\n",
        "    cross_input = [[question, docs[0]] for docs in top_docs_list]\n",
        "    cross_scores = list(cross_encoder_model.predict(cross_input))\n",
        "\n",
        "    # Combine the cross-encoder scores, initial scores, and docs\n",
        "    combined = sorted(zip(cross_scores, [score for _, score in top_docs_list], [content for content, _ in top_docs_list]), reverse=True)\n",
        "\n",
        "    # Extract the sorted docs\n",
        "    sorted_docs = [docs for _, _, docs in combined]\n",
        "\n",
        "    return sorted_docs[0], combined\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Igi78wPBjoa",
        "outputId": "18938619-9998-45d6-efc5-7193059cea9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.50038254,\n",
              "  0.8282816410064697,\n",
              "  '6sense Insights Inc. ( 6sense ) needed to effectively scale and manage its data pipelines so that it could better support its growth . With 6sense Revenue AI , a leading platform for predictable revenue growth , the company generates actionable insights for business - to - business sales and marketing teams . This service relies on artificial intelligence , machine learning , and big data processing , requiring 6sense to run complex workloads and process terabytes of data per day .'),\n",
              " (0.49956676,\n",
              "  0.9839830994606018,\n",
              "  'Headquartered in San Francisco , California , 6sense delivers data analytics , sales insights , and other predictions so that business - to - business revenue teams can better understand their buyers and customers . In 2014 , the company began using Apache Mesos , an open - source solution that manages compute clusters , to orchestrate its data pipeline frameworks . “ As we grew , we encountered several limitations on Apache Mesos , ” says George Liaw , director of infrastructure engineering at 6sense .'),\n",
              " (0.49680158,\n",
              "  0.9619975090026855,\n",
              "  'Using Amazon EKS , 6sense completes workloads significantly faster while reducing management needs , improving its speed of delivery , and freeing its developers to focus on innovative solutions . 6sense Insights Inc. ( 6sense ) needed to effectively scale and manage its data pipelines so that it could better support its growth . With 6sense Revenue AI , a leading platform for predictable revenue growth , the company generates actionable insights for business - to - business sales and marketing teams .'),\n",
              " (0.49603003,\n",
              "  0.9137828350067139,\n",
              "  'Premal Shah Senior Vice President of Engineering and Infrastructure , 6sense Insights Inc. 6sense migrated to Amazon Elastic Kubernetes Service ( Amazon EKS ) , a managed container service to run and scale Kubernetes applications in the cloud or on premises . Using Amazon EKS , 6sense completes workloads significantly faster while reducing management needs , improving its speed of delivery , and freeing its developers to focus on innovative solutions . 6sense Insights Inc. ( 6sense ) needed to effectively scale and manage its data pipelines so that it could better support its growth .')]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_top_docs(\"What did 6Sense use for scaling?\", db, cross_encoder_model, fine_tuned_embed_model)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVr5Yse8GQhr"
      },
      "source": [
        "# Synthetic QA Dataset Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO4CwsBlDOst"
      },
      "source": [
        "## Using Gemini model for QA pair generation\n",
        "\n",
        "We have ~16000 chunks of data. To create a 5 question-answer pair for each chunk with a prompt of 500 tokens, we would need approximately need 17hrs to create a dataset because of Gemini rate limit of Free tier: 15 RPM (requests per minute), 1,500 RPD(requests per day)\n",
        "\n",
        "We'll generate data for 1000 chunks which should take around 1hr.\n",
        "\n",
        "NOTE: We can add temperature range (maybe 0.1 to 1.2) to generate a wide variety of QA pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "dsCBr1VoS6HF",
        "outputId": "10c958ab-d4a9-4ed4-b32a-c7bdc301f1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RWhV_aDfS54y"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash-latest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wGl9gGEfMVkb"
      },
      "outputs": [],
      "source": [
        "qa_gen_prompt= \"\"\"\n",
        "\n",
        "<input-text>\n",
        "\n",
        "{}\n",
        "\n",
        "<input-text>\n",
        "\n",
        "Provide 5 question and answer pair(s) based on the text above. The question should include sufficient information for the answer, without the user having any further context. The answers need not necessarily borrow verbatim from the input text, but they should maintain the meaning. Vary the style and format of questions. Include some tricky and nuanced questions. In certain answers, reverse the order of words compared to how they appear in the input text. Respond in plain text on a new line for each question and answer. Do not include question numbers. Please follow the given formart here in the example question answer pair:\n",
        "\n",
        "<example-start>\n",
        "What cloud services does 54gene use to store and visualize its datasets?\n",
        "54gene uses Amazon Relational Database Service (Amazon RDS) to store and visualize its datasets.\n",
        "\n",
        "How does 54gene utilize Amazon Elastic Compute Cloud (Amazon EC2) in its operations?\n",
        "54gene uses Amazon Elastic Compute Cloud (Amazon EC2) to power its data analytics workflows, enabling it to analyze large datasets efficiently and achieve significant throughput while reducing costs.\n",
        "<example-end>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PLteonxIKAub"
      },
      "outputs": [],
      "source": [
        "test_data = \"\"\"54gene stores all its genomic data using Amazon Simple Storage Service (Amazon S3), object storage built to retrieve any amount of data from anywhere. “Another great aspect of working on AWS is that we can configure data storage to be cost effective,” says Joshi. The company uses Amazon S3 Lifecycle policies to automatically migrate data to Amazon S3 Glacier storage classes—which are purpose-built for data archiving—to minimize storage costs.  To conveniently access data stored in Amazon S3 for processing using HPC clusters, the startup uses Amazon FSx for Lustre, which provides fully managed shared storage built on a popular high-performance file system. And 54gene’s computational scientists, many of whom had trained on traditional on-premises setups, adjusted easily to AWS. “What’s nice about AWS is that we are able to replicate a familiar environment for our computational scientists with minimal cloud training,” says Joshi. “AWS ParallelCluster is a great example of that.”\n",
        "Based in Nigeria, 54gene is a genomics startup that works with pharmaceutical and research partners to study genetic diseases and identify treatments. It’s focused on addressing the need for diverse datasets from underrepresented African populations.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "o0ljJjJsKH65",
        "outputId": "dcdc7613-d515-4e2f-fe86-b46e8553313d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 51.4 ms, sys: 3.22 ms, total: 54.6 ms\n",
            "Wall time: 2.97 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(qa_gen_prompt.format(test_data),\n",
        "                                  generation_config={'temperature': 0.7},\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "zybPyPe_KH3_",
        "outputId": "c6fd5f90-3995-4a7c-bdef-ea9a0fd27cdc"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> What is 54gene's primary focus in terms of its research and development efforts?\n",
              "> 54gene primarily focuses on studying genetic diseases and identifying potential treatments for these diseases.\n",
              "> \n",
              "> How does 54gene leverage AWS to manage its data storage costs?\n",
              "> 54gene utilizes Amazon S3 Lifecycle policies to automatically migrate data to Amazon S3 Glacier storage classes, which are optimized for long-term data archiving, thus minimizing storage costs.\n",
              "> \n",
              "> What specific AWS service does 54gene utilize to enable convenient access to data stored in Amazon S3 for processing using HPC clusters?\n",
              "> 54gene utilizes Amazon FSx for Lustre, a fully managed shared storage solution based on a popular high-performance file system, to facilitate convenient access to data stored in Amazon S3 for processing using HPC clusters.\n",
              "> \n",
              "> Why does 54gene believe that AWS provides a familiar environment for its computational scientists?\n",
              "> 54gene believes that AWS provides a familiar environment for its computational scientists because it enables them to replicate a familiar environment with minimal cloud training, as exemplified by AWS ParallelCluster.\n",
              "> \n",
              "> What specific challenge does 54gene aim to address through its research efforts, particularly concerning the African population?\n",
              "> 54gene aims to address the need for diverse datasets from underrepresented African populations, recognizing the importance of inclusivity in genetic research. \n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(response.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uosfJIG2D6az"
      },
      "source": [
        "## Data Processing and Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "eu8-R5tSUXp8",
        "outputId": "f17906a1-4025-40aa-e078-862fd19531f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunk 1/1000 generated in 2.23s and saved -> synth_data/chunk_1.txt.\n",
            "Chunk 2/1000 generated in 2.48s and saved -> synth_data/chunk_2.txt.\n",
            "Chunk 3/1000 generated in 1.62s and saved -> synth_data/chunk_3.txt.\n",
            "Chunk 4/1000 generated in 1.75s and saved -> synth_data/chunk_4.txt.\n",
            "Chunk 5/1000 generated in 2.15s and saved -> synth_data/chunk_5.txt.\n",
            "Chunk 6/1000 generated in 1.83s and saved -> synth_data/chunk_6.txt.\n",
            "Chunk 7/1000 generated in 1.67s and saved -> synth_data/chunk_7.txt.\n",
            "Chunk 8/1000 generated in 1.83s and saved -> synth_data/chunk_8.txt.\n",
            "Chunk 9/1000 generated in 2.30s and saved -> synth_data/chunk_9.txt.\n",
            "Chunk 10/1000 generated in 1.95s and saved -> synth_data/chunk_10.txt.\n",
            "Chunk 11/1000 generated in 1.32s and saved -> synth_data/chunk_11.txt.\n",
            "Chunk 12/1000 generated in 1.55s and saved -> synth_data/chunk_12.txt.\n",
            "Chunk 13/1000 generated in 2.43s and saved -> synth_data/chunk_13.txt.\n",
            "Chunk 14/1000 generated in 2.18s and saved -> synth_data/chunk_14.txt.\n",
            "Chunk 15/1000 generated in 1.74s and saved -> synth_data/chunk_15.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 16/1000 generated in 1.82s and saved -> synth_data/chunk_16.txt.\n",
            "Chunk 17/1000 generated in 1.85s and saved -> synth_data/chunk_17.txt.\n",
            "Chunk 18/1000 generated in 2.15s and saved -> synth_data/chunk_18.txt.\n",
            "Chunk 19/1000 generated in 1.84s and saved -> synth_data/chunk_19.txt.\n",
            "Chunk 20/1000 generated in 2.32s and saved -> synth_data/chunk_20.txt.\n",
            "Chunk 21/1000 generated in 3.11s and saved -> synth_data/chunk_21.txt.\n",
            "Chunk 22/1000 generated in 2.20s and saved -> synth_data/chunk_22.txt.\n",
            "Chunk 23/1000 generated in 2.22s and saved -> synth_data/chunk_23.txt.\n",
            "Chunk 24/1000 generated in 1.79s and saved -> synth_data/chunk_24.txt.\n",
            "Chunk 25/1000 generated in 2.02s and saved -> synth_data/chunk_25.txt.\n",
            "Chunk 26/1000 generated in 2.38s and saved -> synth_data/chunk_26.txt.\n",
            "Chunk 27/1000 generated in 1.69s and saved -> synth_data/chunk_27.txt.\n",
            "Chunk 28/1000 generated in 1.79s and saved -> synth_data/chunk_28.txt.\n",
            "Chunk 29/1000 generated in 2.00s and saved -> synth_data/chunk_29.txt.\n",
            "Chunk 30/1000 generated in 1.97s and saved -> synth_data/chunk_30.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 31/1000 generated in 2.05s and saved -> synth_data/chunk_31.txt.\n",
            "Chunk 32/1000 generated in 1.92s and saved -> synth_data/chunk_32.txt.\n",
            "Chunk 33/1000 generated in 2.75s and saved -> synth_data/chunk_33.txt.\n",
            "Chunk 34/1000 generated in 2.10s and saved -> synth_data/chunk_34.txt.\n",
            "Chunk 35/1000 generated in 2.17s and saved -> synth_data/chunk_35.txt.\n",
            "Chunk 36/1000 generated in 2.70s and saved -> synth_data/chunk_36.txt.\n",
            "Chunk 37/1000 generated in 2.02s and saved -> synth_data/chunk_37.txt.\n",
            "Chunk 38/1000 generated in 1.90s and saved -> synth_data/chunk_38.txt.\n",
            "Chunk 39/1000 generated in 1.95s and saved -> synth_data/chunk_39.txt.\n",
            "Chunk 40/1000 generated in 1.67s and saved -> synth_data/chunk_40.txt.\n",
            "Chunk 41/1000 generated in 2.20s and saved -> synth_data/chunk_41.txt.\n",
            "Chunk 42/1000 generated in 2.10s and saved -> synth_data/chunk_42.txt.\n",
            "Chunk 43/1000 generated in 1.92s and saved -> synth_data/chunk_43.txt.\n",
            "Chunk 44/1000 generated in 2.42s and saved -> synth_data/chunk_44.txt.\n",
            "Chunk 45/1000 generated in 2.22s and saved -> synth_data/chunk_45.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 46/1000 generated in 2.43s and saved -> synth_data/chunk_46.txt.\n",
            "Chunk 47/1000 generated in 2.05s and saved -> synth_data/chunk_47.txt.\n",
            "Chunk 48/1000 generated in 1.95s and saved -> synth_data/chunk_48.txt.\n",
            "Chunk 49/1000 generated in 2.10s and saved -> synth_data/chunk_49.txt.\n",
            "Chunk 50/1000 generated in 2.61s and saved -> synth_data/chunk_50.txt.\n",
            "Chunk 51/1000 generated in 2.33s and saved -> synth_data/chunk_51.txt.\n",
            "Chunk 52/1000 generated in 1.92s and saved -> synth_data/chunk_52.txt.\n",
            "Chunk 53/1000 generated in 2.38s and saved -> synth_data/chunk_53.txt.\n",
            "Chunk 54/1000 generated in 1.97s and saved -> synth_data/chunk_54.txt.\n",
            "Chunk 55/1000 generated in 1.90s and saved -> synth_data/chunk_55.txt.\n",
            "Chunk 56/1000 generated in 3.00s and saved -> synth_data/chunk_56.txt.\n",
            "Chunk 57/1000 generated in 3.66s and saved -> synth_data/chunk_57.txt.\n",
            "Chunk 58/1000 generated in 1.89s and saved -> synth_data/chunk_58.txt.\n",
            "Chunk 59/1000 generated in 2.12s and saved -> synth_data/chunk_59.txt.\n",
            "Chunk 60/1000 generated in 1.97s and saved -> synth_data/chunk_60.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 61/1000 generated in 2.33s and saved -> synth_data/chunk_61.txt.\n",
            "Chunk 62/1000 generated in 1.95s and saved -> synth_data/chunk_62.txt.\n",
            "Chunk 63/1000 generated in 2.28s and saved -> synth_data/chunk_63.txt.\n",
            "Chunk 64/1000 generated in 2.15s and saved -> synth_data/chunk_64.txt.\n",
            "Chunk 65/1000 generated in 2.45s and saved -> synth_data/chunk_65.txt.\n",
            "Chunk 66/1000 generated in 2.53s and saved -> synth_data/chunk_66.txt.\n",
            "Chunk 67/1000 generated in 1.77s and saved -> synth_data/chunk_67.txt.\n",
            "Chunk 68/1000 generated in 1.64s and saved -> synth_data/chunk_68.txt.\n",
            "Chunk 69/1000 generated in 2.23s and saved -> synth_data/chunk_69.txt.\n",
            "Chunk 70/1000 generated in 2.58s and saved -> synth_data/chunk_70.txt.\n",
            "Chunk 71/1000 generated in 2.22s and saved -> synth_data/chunk_71.txt.\n",
            "Chunk 72/1000 generated in 1.54s and saved -> synth_data/chunk_72.txt.\n",
            "Chunk 73/1000 generated in 1.85s and saved -> synth_data/chunk_73.txt.\n",
            "Chunk 74/1000 generated in 1.97s and saved -> synth_data/chunk_74.txt.\n",
            "Chunk 75/1000 generated in 2.30s and saved -> synth_data/chunk_75.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 76/1000 generated in 2.15s and saved -> synth_data/chunk_76.txt.\n",
            "Chunk 77/1000 generated in 1.82s and saved -> synth_data/chunk_77.txt.\n",
            "Chunk 78/1000 generated in 1.77s and saved -> synth_data/chunk_78.txt.\n",
            "Chunk 79/1000 generated in 1.84s and saved -> synth_data/chunk_79.txt.\n",
            "Chunk 80/1000 generated in 3.28s and saved -> synth_data/chunk_80.txt.\n",
            "Chunk 81/1000 generated in 2.62s and saved -> synth_data/chunk_81.txt.\n",
            "Chunk 82/1000 generated in 1.85s and saved -> synth_data/chunk_82.txt.\n",
            "Chunk 83/1000 generated in 1.74s and saved -> synth_data/chunk_83.txt.\n",
            "Chunk 84/1000 generated in 2.27s and saved -> synth_data/chunk_84.txt.\n",
            "Chunk 85/1000 generated in 1.97s and saved -> synth_data/chunk_85.txt.\n",
            "Chunk 86/1000 generated in 1.90s and saved -> synth_data/chunk_86.txt.\n",
            "Chunk 87/1000 generated in 2.50s and saved -> synth_data/chunk_87.txt.\n",
            "Chunk 88/1000 generated in 2.37s and saved -> synth_data/chunk_88.txt.\n",
            "Chunk 89/1000 generated in 2.05s and saved -> synth_data/chunk_89.txt.\n",
            "Chunk 90/1000 generated in 2.40s and saved -> synth_data/chunk_90.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 91/1000 generated in 2.12s and saved -> synth_data/chunk_91.txt.\n",
            "Chunk 92/1000 generated in 1.94s and saved -> synth_data/chunk_92.txt.\n",
            "Chunk 93/1000 generated in 1.97s and saved -> synth_data/chunk_93.txt.\n",
            "Chunk 94/1000 generated in 1.69s and saved -> synth_data/chunk_94.txt.\n",
            "Chunk 95/1000 generated in 1.49s and saved -> synth_data/chunk_95.txt.\n",
            "Chunk 96/1000 generated in 1.87s and saved -> synth_data/chunk_96.txt.\n",
            "Chunk 97/1000 generated in 2.27s and saved -> synth_data/chunk_97.txt.\n",
            "Chunk 98/1000 generated in 1.74s and saved -> synth_data/chunk_98.txt.\n",
            "Chunk 99/1000 generated in 1.72s and saved -> synth_data/chunk_99.txt.\n",
            "Chunk 100/1000 generated in 2.35s and saved -> synth_data/chunk_100.txt.\n",
            "Chunk 101/1000 generated in 2.30s and saved -> synth_data/chunk_101.txt.\n",
            "Chunk 102/1000 generated in 2.05s and saved -> synth_data/chunk_102.txt.\n",
            "Chunk 103/1000 generated in 2.35s and saved -> synth_data/chunk_103.txt.\n",
            "Chunk 104/1000 generated in 2.00s and saved -> synth_data/chunk_104.txt.\n",
            "Chunk 105/1000 generated in 2.17s and saved -> synth_data/chunk_105.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 106/1000 generated in 1.80s and saved -> synth_data/chunk_106.txt.\n",
            "Chunk 107/1000 generated in 1.54s and saved -> synth_data/chunk_107.txt.\n",
            "Chunk 108/1000 generated in 2.25s and saved -> synth_data/chunk_108.txt.\n",
            "Chunk 109/1000 generated in 2.53s and saved -> synth_data/chunk_109.txt.\n",
            "Chunk 110/1000 generated in 1.92s and saved -> synth_data/chunk_110.txt.\n",
            "Chunk 111/1000 generated in 1.47s and saved -> synth_data/chunk_111.txt.\n",
            "Chunk 112/1000 generated in 2.15s and saved -> synth_data/chunk_112.txt.\n",
            "Chunk 113/1000 generated in 2.45s and saved -> synth_data/chunk_113.txt.\n",
            "Chunk 114/1000 generated in 2.20s and saved -> synth_data/chunk_114.txt.\n",
            "Chunk 115/1000 generated in 2.07s and saved -> synth_data/chunk_115.txt.\n",
            "Chunk 116/1000 generated in 1.80s and saved -> synth_data/chunk_116.txt.\n",
            "Chunk 117/1000 generated in 3.66s and saved -> synth_data/chunk_117.txt.\n",
            "Chunk 118/1000 generated in 2.10s and saved -> synth_data/chunk_118.txt.\n",
            "Chunk 119/1000 generated in 2.05s and saved -> synth_data/chunk_119.txt.\n",
            "Chunk 120/1000 generated in 2.25s and saved -> synth_data/chunk_120.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 121/1000 generated in 2.45s and saved -> synth_data/chunk_121.txt.\n",
            "Chunk 122/1000 generated in 2.15s and saved -> synth_data/chunk_122.txt.\n",
            "Chunk 123/1000 generated in 2.20s and saved -> synth_data/chunk_123.txt.\n",
            "Chunk 124/1000 generated in 1.57s and saved -> synth_data/chunk_124.txt.\n",
            "Chunk 125/1000 generated in 1.90s and saved -> synth_data/chunk_125.txt.\n",
            "Chunk 126/1000 generated in 2.50s and saved -> synth_data/chunk_126.txt.\n",
            "Chunk 127/1000 generated in 2.20s and saved -> synth_data/chunk_127.txt.\n",
            "Chunk 128/1000 generated in 1.59s and saved -> synth_data/chunk_128.txt.\n",
            "Chunk 129/1000 generated in 2.48s and saved -> synth_data/chunk_129.txt.\n",
            "Chunk 130/1000 generated in 2.53s and saved -> synth_data/chunk_130.txt.\n",
            "Chunk 131/1000 generated in 2.47s and saved -> synth_data/chunk_131.txt.\n",
            "Chunk 132/1000 generated in 2.18s and saved -> synth_data/chunk_132.txt.\n",
            "Chunk 133/1000 generated in 1.77s and saved -> synth_data/chunk_133.txt.\n",
            "Chunk 134/1000 generated in 2.38s and saved -> synth_data/chunk_134.txt.\n",
            "Chunk 135/1000 generated in 2.40s and saved -> synth_data/chunk_135.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 136/1000 generated in 2.35s and saved -> synth_data/chunk_136.txt.\n",
            "Chunk 137/1000 generated in 1.72s and saved -> synth_data/chunk_137.txt.\n",
            "Chunk 138/1000 generated in 2.17s and saved -> synth_data/chunk_138.txt.\n",
            "Chunk 139/1000 generated in 2.68s and saved -> synth_data/chunk_139.txt.\n",
            "Chunk 140/1000 generated in 1.57s and saved -> synth_data/chunk_140.txt.\n",
            "Chunk 141/1000 generated in 2.22s and saved -> synth_data/chunk_141.txt.\n",
            "Chunk 142/1000 generated in 2.58s and saved -> synth_data/chunk_142.txt.\n",
            "Chunk 143/1000 generated in 2.55s and saved -> synth_data/chunk_143.txt.\n",
            "Chunk 144/1000 generated in 1.89s and saved -> synth_data/chunk_144.txt.\n",
            "Chunk 145/1000 generated in 2.04s and saved -> synth_data/chunk_145.txt.\n",
            "Chunk 146/1000 generated in 2.02s and saved -> synth_data/chunk_146.txt.\n",
            "Chunk 147/1000 generated in 2.02s and saved -> synth_data/chunk_147.txt.\n",
            "Chunk 148/1000 generated in 2.29s and saved -> synth_data/chunk_148.txt.\n",
            "Chunk 149/1000 generated in 1.97s and saved -> synth_data/chunk_149.txt.\n",
            "Chunk 150/1000 generated in 2.20s and saved -> synth_data/chunk_150.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 151/1000 generated in 1.85s and saved -> synth_data/chunk_151.txt.\n",
            "Chunk 152/1000 generated in 2.00s and saved -> synth_data/chunk_152.txt.\n",
            "Chunk 153/1000 generated in 1.42s and saved -> synth_data/chunk_153.txt.\n",
            "Chunk 154/1000 generated in 2.75s and saved -> synth_data/chunk_154.txt.\n",
            "Chunk 155/1000 generated in 1.92s and saved -> synth_data/chunk_155.txt.\n",
            "Chunk 156/1000 generated in 2.10s and saved -> synth_data/chunk_156.txt.\n",
            "Chunk 157/1000 generated in 1.97s and saved -> synth_data/chunk_157.txt.\n",
            "Chunk 158/1000 generated in 1.87s and saved -> synth_data/chunk_158.txt.\n",
            "Chunk 159/1000 generated in 2.05s and saved -> synth_data/chunk_159.txt.\n",
            "Chunk 160/1000 generated in 2.30s and saved -> synth_data/chunk_160.txt.\n",
            "Chunk 161/1000 generated in 2.20s and saved -> synth_data/chunk_161.txt.\n",
            "Chunk 162/1000 generated in 2.05s and saved -> synth_data/chunk_162.txt.\n",
            "Chunk 163/1000 generated in 1.60s and saved -> synth_data/chunk_163.txt.\n",
            "Chunk 164/1000 generated in 3.00s and saved -> synth_data/chunk_164.txt.\n",
            "Chunk 165/1000 generated in 2.17s and saved -> synth_data/chunk_165.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 166/1000 generated in 1.67s and saved -> synth_data/chunk_166.txt.\n",
            "Chunk 167/1000 generated in 2.30s and saved -> synth_data/chunk_167.txt.\n",
            "Chunk 168/1000 generated in 2.20s and saved -> synth_data/chunk_168.txt.\n",
            "Chunk 169/1000 generated in 2.17s and saved -> synth_data/chunk_169.txt.\n",
            "Chunk 170/1000 generated in 2.00s and saved -> synth_data/chunk_170.txt.\n",
            "Chunk 171/1000 generated in 2.02s and saved -> synth_data/chunk_171.txt.\n",
            "Chunk 172/1000 generated in 2.22s and saved -> synth_data/chunk_172.txt.\n",
            "Chunk 173/1000 generated in 2.07s and saved -> synth_data/chunk_173.txt.\n",
            "Chunk 174/1000 generated in 2.45s and saved -> synth_data/chunk_174.txt.\n",
            "Chunk 175/1000 generated in 2.20s and saved -> synth_data/chunk_175.txt.\n",
            "Chunk 176/1000 generated in 2.48s and saved -> synth_data/chunk_176.txt.\n",
            "Chunk 177/1000 generated in 2.32s and saved -> synth_data/chunk_177.txt.\n",
            "Chunk 178/1000 generated in 2.60s and saved -> synth_data/chunk_178.txt.\n",
            "Chunk 179/1000 generated in 2.02s and saved -> synth_data/chunk_179.txt.\n",
            "Chunk 180/1000 generated in 1.82s and saved -> synth_data/chunk_180.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 181/1000 generated in 2.10s and saved -> synth_data/chunk_181.txt.\n",
            "Chunk 182/1000 generated in 2.43s and saved -> synth_data/chunk_182.txt.\n",
            "Chunk 183/1000 generated in 1.77s and saved -> synth_data/chunk_183.txt.\n",
            "Chunk 184/1000 generated in 3.48s and saved -> synth_data/chunk_184.txt.\n",
            "Chunk 185/1000 generated in 1.77s and saved -> synth_data/chunk_185.txt.\n",
            "Chunk 186/1000 generated in 1.54s and saved -> synth_data/chunk_186.txt.\n",
            "Chunk 187/1000 generated in 1.52s and saved -> synth_data/chunk_187.txt.\n",
            "Chunk 188/1000 generated in 2.20s and saved -> synth_data/chunk_188.txt.\n",
            "Chunk 189/1000 generated in 1.65s and saved -> synth_data/chunk_189.txt.\n",
            "Chunk 190/1000 generated in 2.12s and saved -> synth_data/chunk_190.txt.\n",
            "Chunk 191/1000 generated in 1.90s and saved -> synth_data/chunk_191.txt.\n",
            "Chunk 192/1000 generated in 2.10s and saved -> synth_data/chunk_192.txt.\n",
            "Chunk 193/1000 generated in 2.45s and saved -> synth_data/chunk_193.txt.\n",
            "Chunk 194/1000 generated in 1.97s and saved -> synth_data/chunk_194.txt.\n",
            "Chunk 195/1000 generated in 2.32s and saved -> synth_data/chunk_195.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 196/1000 generated in 1.77s and saved -> synth_data/chunk_196.txt.\n",
            "Chunk 197/1000 generated in 1.92s and saved -> synth_data/chunk_197.txt.\n",
            "Chunk 198/1000 generated in 2.20s and saved -> synth_data/chunk_198.txt.\n",
            "Chunk 199/1000 generated in 1.59s and saved -> synth_data/chunk_199.txt.\n",
            "Chunk 200/1000 generated in 1.77s and saved -> synth_data/chunk_200.txt.\n",
            "Chunk 201/1000 generated in 2.37s and saved -> synth_data/chunk_201.txt.\n",
            "Chunk 202/1000 generated in 1.97s and saved -> synth_data/chunk_202.txt.\n",
            "Chunk 203/1000 generated in 2.17s and saved -> synth_data/chunk_203.txt.\n",
            "Chunk 204/1000 generated in 1.79s and saved -> synth_data/chunk_204.txt.\n",
            "Chunk 205/1000 generated in 2.20s and saved -> synth_data/chunk_205.txt.\n",
            "Chunk 206/1000 generated in 2.17s and saved -> synth_data/chunk_206.txt.\n",
            "Chunk 207/1000 generated in 2.43s and saved -> synth_data/chunk_207.txt.\n",
            "Chunk 208/1000 generated in 2.43s and saved -> synth_data/chunk_208.txt.\n",
            "Chunk 209/1000 generated in 1.57s and saved -> synth_data/chunk_209.txt.\n",
            "Chunk 210/1000 generated in 2.68s and saved -> synth_data/chunk_210.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 211/1000 generated in 2.38s and saved -> synth_data/chunk_211.txt.\n",
            "Chunk 212/1000 generated in 2.43s and saved -> synth_data/chunk_212.txt.\n",
            "Chunk 213/1000 generated in 2.22s and saved -> synth_data/chunk_213.txt.\n",
            "Chunk 214/1000 generated in 1.99s and saved -> synth_data/chunk_214.txt.\n",
            "Chunk 215/1000 generated in 2.02s and saved -> synth_data/chunk_215.txt.\n",
            "Chunk 216/1000 generated in 1.95s and saved -> synth_data/chunk_216.txt.\n",
            "Chunk 217/1000 generated in 2.00s and saved -> synth_data/chunk_217.txt.\n",
            "Chunk 218/1000 generated in 1.75s and saved -> synth_data/chunk_218.txt.\n",
            "Chunk 219/1000 generated in 3.05s and saved -> synth_data/chunk_219.txt.\n",
            "Chunk 220/1000 generated in 2.15s and saved -> synth_data/chunk_220.txt.\n",
            "Chunk 221/1000 generated in 2.40s and saved -> synth_data/chunk_221.txt.\n",
            "Chunk 222/1000 generated in 3.06s and saved -> synth_data/chunk_222.txt.\n",
            "Chunk 223/1000 generated in 1.99s and saved -> synth_data/chunk_223.txt.\n",
            "Chunk 224/1000 generated in 2.40s and saved -> synth_data/chunk_224.txt.\n",
            "Chunk 225/1000 generated in 2.37s and saved -> synth_data/chunk_225.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 226/1000 generated in 2.73s and saved -> synth_data/chunk_226.txt.\n",
            "Chunk 227/1000 generated in 1.72s and saved -> synth_data/chunk_227.txt.\n",
            "Chunk 228/1000 generated in 2.93s and saved -> synth_data/chunk_228.txt.\n",
            "Chunk 229/1000 generated in 1.72s and saved -> synth_data/chunk_229.txt.\n",
            "Chunk 230/1000 generated in 1.77s and saved -> synth_data/chunk_230.txt.\n",
            "Chunk 231/1000 generated in 2.88s and saved -> synth_data/chunk_231.txt.\n",
            "Chunk 232/1000 generated in 2.47s and saved -> synth_data/chunk_232.txt.\n",
            "Chunk 233/1000 generated in 2.00s and saved -> synth_data/chunk_233.txt.\n",
            "Chunk 234/1000 generated in 1.90s and saved -> synth_data/chunk_234.txt.\n",
            "Chunk 235/1000 generated in 2.47s and saved -> synth_data/chunk_235.txt.\n",
            "Chunk 236/1000 generated in 2.20s and saved -> synth_data/chunk_236.txt.\n",
            "Chunk 237/1000 generated in 2.32s and saved -> synth_data/chunk_237.txt.\n",
            "Chunk 238/1000 generated in 2.00s and saved -> synth_data/chunk_238.txt.\n",
            "Chunk 239/1000 generated in 1.75s and saved -> synth_data/chunk_239.txt.\n",
            "Chunk 240/1000 generated in 1.70s and saved -> synth_data/chunk_240.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 241/1000 generated in 1.82s and saved -> synth_data/chunk_241.txt.\n",
            "Chunk 242/1000 generated in 2.35s and saved -> synth_data/chunk_242.txt.\n",
            "Chunk 243/1000 generated in 2.17s and saved -> synth_data/chunk_243.txt.\n",
            "Chunk 244/1000 generated in 2.22s and saved -> synth_data/chunk_244.txt.\n",
            "Chunk 245/1000 generated in 2.58s and saved -> synth_data/chunk_245.txt.\n",
            "Chunk 246/1000 generated in 3.36s and saved -> synth_data/chunk_246.txt.\n",
            "Chunk 247/1000 generated in 2.22s and saved -> synth_data/chunk_247.txt.\n",
            "Chunk 248/1000 generated in 1.82s and saved -> synth_data/chunk_248.txt.\n",
            "Chunk 249/1000 generated in 1.85s and saved -> synth_data/chunk_249.txt.\n",
            "Chunk 250/1000 generated in 2.32s and saved -> synth_data/chunk_250.txt.\n",
            "Chunk 251/1000 generated in 1.87s and saved -> synth_data/chunk_251.txt.\n",
            "Chunk 252/1000 generated in 1.95s and saved -> synth_data/chunk_252.txt.\n",
            "Chunk 253/1000 generated in 2.60s and saved -> synth_data/chunk_253.txt.\n",
            "Chunk 254/1000 generated in 1.92s and saved -> synth_data/chunk_254.txt.\n",
            "Chunk 255/1000 generated in 1.74s and saved -> synth_data/chunk_255.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 256/1000 generated in 2.02s and saved -> synth_data/chunk_256.txt.\n",
            "Chunk 257/1000 generated in 2.10s and saved -> synth_data/chunk_257.txt.\n",
            "Chunk 258/1000 generated in 2.20s and saved -> synth_data/chunk_258.txt.\n",
            "Chunk 259/1000 generated in 1.97s and saved -> synth_data/chunk_259.txt.\n",
            "Chunk 260/1000 generated in 2.20s and saved -> synth_data/chunk_260.txt.\n",
            "Chunk 261/1000 generated in 2.12s and saved -> synth_data/chunk_261.txt.\n",
            "Chunk 262/1000 generated in 1.89s and saved -> synth_data/chunk_262.txt.\n",
            "Chunk 263/1000 generated in 1.99s and saved -> synth_data/chunk_263.txt.\n",
            "Chunk 264/1000 generated in 1.94s and saved -> synth_data/chunk_264.txt.\n",
            "Chunk 265/1000 generated in 1.89s and saved -> synth_data/chunk_265.txt.\n",
            "Chunk 266/1000 generated in 1.82s and saved -> synth_data/chunk_266.txt.\n",
            "Chunk 267/1000 generated in 2.02s and saved -> synth_data/chunk_267.txt.\n",
            "Chunk 268/1000 generated in 2.55s and saved -> synth_data/chunk_268.txt.\n",
            "Chunk 269/1000 generated in 1.62s and saved -> synth_data/chunk_269.txt.\n",
            "Chunk 270/1000 generated in 2.10s and saved -> synth_data/chunk_270.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 271/1000 generated in 1.70s and saved -> synth_data/chunk_271.txt.\n",
            "Chunk 272/1000 generated in 2.25s and saved -> synth_data/chunk_272.txt.\n",
            "Chunk 273/1000 generated in 1.92s and saved -> synth_data/chunk_273.txt.\n",
            "Chunk 274/1000 generated in 2.05s and saved -> synth_data/chunk_274.txt.\n",
            "Chunk 275/1000 generated in 2.22s and saved -> synth_data/chunk_275.txt.\n",
            "Chunk 276/1000 generated in 1.94s and saved -> synth_data/chunk_276.txt.\n",
            "Chunk 277/1000 generated in 1.90s and saved -> synth_data/chunk_277.txt.\n",
            "Chunk 278/1000 generated in 2.05s and saved -> synth_data/chunk_278.txt.\n",
            "Chunk 279/1000 generated in 1.84s and saved -> synth_data/chunk_279.txt.\n",
            "Chunk 280/1000 generated in 2.37s and saved -> synth_data/chunk_280.txt.\n",
            "Chunk 281/1000 generated in 2.20s and saved -> synth_data/chunk_281.txt.\n",
            "Chunk 282/1000 generated in 1.84s and saved -> synth_data/chunk_282.txt.\n",
            "Chunk 283/1000 generated in 2.45s and saved -> synth_data/chunk_283.txt.\n",
            "Chunk 284/1000 generated in 1.97s and saved -> synth_data/chunk_284.txt.\n",
            "Chunk 285/1000 generated in 1.59s and saved -> synth_data/chunk_285.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 286/1000 generated in 2.37s and saved -> synth_data/chunk_286.txt.\n",
            "Chunk 287/1000 generated in 2.07s and saved -> synth_data/chunk_287.txt.\n",
            "Chunk 288/1000 generated in 1.47s and saved -> synth_data/chunk_288.txt.\n",
            "Chunk 289/1000 generated in 1.84s and saved -> synth_data/chunk_289.txt.\n",
            "Chunk 290/1000 generated in 2.67s and saved -> synth_data/chunk_290.txt.\n",
            "Chunk 291/1000 generated in 1.97s and saved -> synth_data/chunk_291.txt.\n",
            "Chunk 292/1000 generated in 2.07s and saved -> synth_data/chunk_292.txt.\n",
            "Chunk 293/1000 generated in 1.87s and saved -> synth_data/chunk_293.txt.\n",
            "Chunk 294/1000 generated in 2.05s and saved -> synth_data/chunk_294.txt.\n",
            "Chunk 295/1000 generated in 1.97s and saved -> synth_data/chunk_295.txt.\n",
            "Chunk 296/1000 generated in 2.07s and saved -> synth_data/chunk_296.txt.\n",
            "Chunk 297/1000 generated in 2.10s and saved -> synth_data/chunk_297.txt.\n",
            "Chunk 298/1000 generated in 2.42s and saved -> synth_data/chunk_298.txt.\n",
            "Chunk 299/1000 generated in 2.20s and saved -> synth_data/chunk_299.txt.\n",
            "Chunk 300/1000 generated in 2.45s and saved -> synth_data/chunk_300.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 301/1000 generated in 2.17s and saved -> synth_data/chunk_301.txt.\n",
            "Chunk 302/1000 generated in 1.69s and saved -> synth_data/chunk_302.txt.\n",
            "Chunk 303/1000 generated in 1.59s and saved -> synth_data/chunk_303.txt.\n",
            "Chunk 304/1000 generated in 1.82s and saved -> synth_data/chunk_304.txt.\n",
            "Chunk 305/1000 generated in 2.22s and saved -> synth_data/chunk_305.txt.\n",
            "Chunk 306/1000 generated in 1.94s and saved -> synth_data/chunk_306.txt.\n",
            "Chunk 307/1000 generated in 2.02s and saved -> synth_data/chunk_307.txt.\n",
            "Chunk 308/1000 generated in 2.91s and saved -> synth_data/chunk_308.txt.\n",
            "Chunk 309/1000 generated in 1.97s and saved -> synth_data/chunk_309.txt.\n",
            "Chunk 310/1000 generated in 1.82s and saved -> synth_data/chunk_310.txt.\n",
            "Chunk 311/1000 generated in 2.10s and saved -> synth_data/chunk_311.txt.\n",
            "Chunk 312/1000 generated in 2.55s and saved -> synth_data/chunk_312.txt.\n",
            "Chunk 313/1000 generated in 2.22s and saved -> synth_data/chunk_313.txt.\n",
            "Chunk 314/1000 generated in 1.59s and saved -> synth_data/chunk_314.txt.\n",
            "Chunk 315/1000 generated in 1.95s and saved -> synth_data/chunk_315.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 316/1000 generated in 1.77s and saved -> synth_data/chunk_316.txt.\n",
            "Chunk 317/1000 generated in 1.87s and saved -> synth_data/chunk_317.txt.\n",
            "Chunk 318/1000 generated in 2.02s and saved -> synth_data/chunk_318.txt.\n",
            "Chunk 319/1000 generated in 2.40s and saved -> synth_data/chunk_319.txt.\n",
            "Chunk 320/1000 generated in 2.00s and saved -> synth_data/chunk_320.txt.\n",
            "Chunk 321/1000 generated in 1.85s and saved -> synth_data/chunk_321.txt.\n",
            "Chunk 322/1000 generated in 2.20s and saved -> synth_data/chunk_322.txt.\n",
            "Chunk 323/1000 generated in 1.97s and saved -> synth_data/chunk_323.txt.\n",
            "Chunk 324/1000 generated in 2.00s and saved -> synth_data/chunk_324.txt.\n",
            "Chunk 325/1000 generated in 1.77s and saved -> synth_data/chunk_325.txt.\n",
            "Chunk 326/1000 generated in 2.75s and saved -> synth_data/chunk_326.txt.\n",
            "Chunk 327/1000 generated in 1.84s and saved -> synth_data/chunk_327.txt.\n",
            "Chunk 328/1000 generated in 2.58s and saved -> synth_data/chunk_328.txt.\n",
            "Chunk 329/1000 generated in 2.27s and saved -> synth_data/chunk_329.txt.\n",
            "Chunk 330/1000 generated in 1.89s and saved -> synth_data/chunk_330.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 331/1000 generated in 2.43s and saved -> synth_data/chunk_331.txt.\n",
            "Chunk 332/1000 generated in 1.77s and saved -> synth_data/chunk_332.txt.\n",
            "Chunk 333/1000 generated in 2.30s and saved -> synth_data/chunk_333.txt.\n",
            "Chunk 334/1000 generated in 1.89s and saved -> synth_data/chunk_334.txt.\n",
            "Chunk 335/1000 generated in 2.10s and saved -> synth_data/chunk_335.txt.\n",
            "Chunk 336/1000 generated in 1.59s and saved -> synth_data/chunk_336.txt.\n",
            "Chunk 337/1000 generated in 1.54s and saved -> synth_data/chunk_337.txt.\n",
            "Chunk 338/1000 generated in 1.90s and saved -> synth_data/chunk_338.txt.\n",
            "Chunk 339/1000 generated in 2.17s and saved -> synth_data/chunk_339.txt.\n",
            "Chunk 340/1000 generated in 2.10s and saved -> synth_data/chunk_340.txt.\n",
            "Chunk 341/1000 generated in 2.20s and saved -> synth_data/chunk_341.txt.\n",
            "Chunk 342/1000 generated in 2.02s and saved -> synth_data/chunk_342.txt.\n",
            "Chunk 343/1000 generated in 1.49s and saved -> synth_data/chunk_343.txt.\n",
            "Chunk 344/1000 generated in 2.22s and saved -> synth_data/chunk_344.txt.\n",
            "Chunk 345/1000 generated in 2.00s and saved -> synth_data/chunk_345.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 346/1000 generated in 2.38s and saved -> synth_data/chunk_346.txt.\n",
            "Chunk 347/1000 generated in 2.43s and saved -> synth_data/chunk_347.txt.\n",
            "Chunk 348/1000 generated in 1.97s and saved -> synth_data/chunk_348.txt.\n",
            "Chunk 349/1000 generated in 1.85s and saved -> synth_data/chunk_349.txt.\n",
            "Chunk 350/1000 generated in 2.30s and saved -> synth_data/chunk_350.txt.\n",
            "Chunk 351/1000 generated in 1.57s and saved -> synth_data/chunk_351.txt.\n",
            "Chunk 352/1000 generated in 2.09s and saved -> synth_data/chunk_352.txt.\n",
            "Chunk 353/1000 generated in 1.79s and saved -> synth_data/chunk_353.txt.\n",
            "Chunk 354/1000 generated in 2.22s and saved -> synth_data/chunk_354.txt.\n",
            "Chunk 355/1000 generated in 2.09s and saved -> synth_data/chunk_355.txt.\n",
            "Chunk 356/1000 generated in 2.02s and saved -> synth_data/chunk_356.txt.\n",
            "Chunk 357/1000 generated in 2.28s and saved -> synth_data/chunk_357.txt.\n",
            "Chunk 358/1000 generated in 2.70s and saved -> synth_data/chunk_358.txt.\n",
            "Chunk 359/1000 generated in 2.45s and saved -> synth_data/chunk_359.txt.\n",
            "Chunk 360/1000 generated in 2.30s and saved -> synth_data/chunk_360.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 361/1000 generated in 2.27s and saved -> synth_data/chunk_361.txt.\n",
            "Chunk 362/1000 generated in 2.17s and saved -> synth_data/chunk_362.txt.\n",
            "Chunk 363/1000 generated in 1.97s and saved -> synth_data/chunk_363.txt.\n",
            "Chunk 364/1000 generated in 2.58s and saved -> synth_data/chunk_364.txt.\n",
            "Chunk 365/1000 generated in 2.22s and saved -> synth_data/chunk_365.txt.\n",
            "Chunk 366/1000 generated in 1.85s and saved -> synth_data/chunk_366.txt.\n",
            "Chunk 367/1000 generated in 2.50s and saved -> synth_data/chunk_367.txt.\n",
            "Chunk 368/1000 generated in 1.95s and saved -> synth_data/chunk_368.txt.\n",
            "Chunk 369/1000 generated in 1.57s and saved -> synth_data/chunk_369.txt.\n",
            "Chunk 370/1000 generated in 2.22s and saved -> synth_data/chunk_370.txt.\n",
            "Chunk 371/1000 generated in 1.97s and saved -> synth_data/chunk_371.txt.\n",
            "Chunk 372/1000 generated in 1.99s and saved -> synth_data/chunk_372.txt.\n",
            "Chunk 373/1000 generated in 2.67s and saved -> synth_data/chunk_373.txt.\n",
            "Chunk 374/1000 generated in 2.25s and saved -> synth_data/chunk_374.txt.\n",
            "Chunk 375/1000 generated in 1.84s and saved -> synth_data/chunk_375.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 376/1000 generated in 2.50s and saved -> synth_data/chunk_376.txt.\n",
            "Chunk 377/1000 generated in 1.77s and saved -> synth_data/chunk_377.txt.\n",
            "Chunk 378/1000 generated in 2.12s and saved -> synth_data/chunk_378.txt.\n",
            "Chunk 379/1000 generated in 2.35s and saved -> synth_data/chunk_379.txt.\n",
            "Chunk 380/1000 generated in 2.22s and saved -> synth_data/chunk_380.txt.\n",
            "Chunk 381/1000 generated in 2.42s and saved -> synth_data/chunk_381.txt.\n",
            "Chunk 382/1000 generated in 2.42s and saved -> synth_data/chunk_382.txt.\n",
            "Chunk 383/1000 generated in 2.68s and saved -> synth_data/chunk_383.txt.\n",
            "Chunk 384/1000 generated in 2.33s and saved -> synth_data/chunk_384.txt.\n",
            "Chunk 385/1000 generated in 1.69s and saved -> synth_data/chunk_385.txt.\n",
            "Chunk 386/1000 generated in 1.87s and saved -> synth_data/chunk_386.txt.\n",
            "Chunk 387/1000 generated in 2.50s and saved -> synth_data/chunk_387.txt.\n",
            "Chunk 388/1000 generated in 2.20s and saved -> synth_data/chunk_388.txt.\n",
            "Chunk 389/1000 generated in 2.30s and saved -> synth_data/chunk_389.txt.\n",
            "Chunk 390/1000 generated in 2.07s and saved -> synth_data/chunk_390.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 391/1000 generated in 2.60s and saved -> synth_data/chunk_391.txt.\n",
            "Chunk 392/1000 generated in 1.92s and saved -> synth_data/chunk_392.txt.\n",
            "Chunk 393/1000 generated in 2.27s and saved -> synth_data/chunk_393.txt.\n",
            "Chunk 394/1000 generated in 2.63s and saved -> synth_data/chunk_394.txt.\n",
            "Chunk 395/1000 generated in 2.05s and saved -> synth_data/chunk_395.txt.\n",
            "Chunk 396/1000 generated in 2.27s and saved -> synth_data/chunk_396.txt.\n",
            "Chunk 397/1000 generated in 2.15s and saved -> synth_data/chunk_397.txt.\n",
            "Chunk 398/1000 generated in 2.12s and saved -> synth_data/chunk_398.txt.\n",
            "Chunk 399/1000 generated in 2.10s and saved -> synth_data/chunk_399.txt.\n",
            "Chunk 400/1000 generated in 2.27s and saved -> synth_data/chunk_400.txt.\n",
            "Chunk 401/1000 generated in 1.84s and saved -> synth_data/chunk_401.txt.\n",
            "Chunk 402/1000 generated in 2.30s and saved -> synth_data/chunk_402.txt.\n",
            "Chunk 403/1000 generated in 1.97s and saved -> synth_data/chunk_403.txt.\n",
            "Chunk 404/1000 generated in 2.30s and saved -> synth_data/chunk_404.txt.\n",
            "Chunk 405/1000 generated in 2.09s and saved -> synth_data/chunk_405.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 406/1000 generated in 2.42s and saved -> synth_data/chunk_406.txt.\n",
            "Chunk 407/1000 generated in 1.89s and saved -> synth_data/chunk_407.txt.\n",
            "Chunk 408/1000 generated in 2.07s and saved -> synth_data/chunk_408.txt.\n",
            "Chunk 409/1000 generated in 1.87s and saved -> synth_data/chunk_409.txt.\n",
            "Chunk 410/1000 generated in 2.27s and saved -> synth_data/chunk_410.txt.\n",
            "Chunk 411/1000 generated in 2.53s and saved -> synth_data/chunk_411.txt.\n",
            "Chunk 412/1000 generated in 1.90s and saved -> synth_data/chunk_412.txt.\n",
            "Chunk 413/1000 generated in 2.27s and saved -> synth_data/chunk_413.txt.\n",
            "Chunk 414/1000 generated in 1.99s and saved -> synth_data/chunk_414.txt.\n",
            "Chunk 415/1000 generated in 2.50s and saved -> synth_data/chunk_415.txt.\n",
            "Chunk 416/1000 generated in 2.12s and saved -> synth_data/chunk_416.txt.\n",
            "Chunk 417/1000 generated in 2.47s and saved -> synth_data/chunk_417.txt.\n",
            "Chunk 418/1000 generated in 2.85s and saved -> synth_data/chunk_418.txt.\n",
            "Chunk 419/1000 generated in 2.17s and saved -> synth_data/chunk_419.txt.\n",
            "Chunk 420/1000 generated in 2.22s and saved -> synth_data/chunk_420.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 421/1000 generated in 1.87s and saved -> synth_data/chunk_421.txt.\n",
            "Chunk 422/1000 generated in 2.35s and saved -> synth_data/chunk_422.txt.\n",
            "Chunk 423/1000 generated in 2.17s and saved -> synth_data/chunk_423.txt.\n",
            "Chunk 424/1000 generated in 1.90s and saved -> synth_data/chunk_424.txt.\n",
            "Chunk 425/1000 generated in 2.28s and saved -> synth_data/chunk_425.txt.\n",
            "Chunk 426/1000 generated in 1.87s and saved -> synth_data/chunk_426.txt.\n",
            "Chunk 427/1000 generated in 1.97s and saved -> synth_data/chunk_427.txt.\n",
            "Chunk 428/1000 generated in 1.97s and saved -> synth_data/chunk_428.txt.\n",
            "Chunk 429/1000 generated in 1.97s and saved -> synth_data/chunk_429.txt.\n",
            "Chunk 430/1000 generated in 2.37s and saved -> synth_data/chunk_430.txt.\n",
            "Chunk 431/1000 generated in 2.12s and saved -> synth_data/chunk_431.txt.\n",
            "Chunk 432/1000 generated in 2.50s and saved -> synth_data/chunk_432.txt.\n",
            "Chunk 433/1000 generated in 1.77s and saved -> synth_data/chunk_433.txt.\n",
            "Chunk 434/1000 generated in 1.72s and saved -> synth_data/chunk_434.txt.\n",
            "Chunk 435/1000 generated in 2.27s and saved -> synth_data/chunk_435.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 436/1000 generated in 2.47s and saved -> synth_data/chunk_436.txt.\n",
            "Chunk 437/1000 generated in 1.84s and saved -> synth_data/chunk_437.txt.\n",
            "Chunk 438/1000 generated in 2.22s and saved -> synth_data/chunk_438.txt.\n",
            "Chunk 439/1000 generated in 2.37s and saved -> synth_data/chunk_439.txt.\n",
            "Chunk 440/1000 generated in 2.42s and saved -> synth_data/chunk_440.txt.\n",
            "Chunk 441/1000 generated in 2.12s and saved -> synth_data/chunk_441.txt.\n",
            "Chunk 442/1000 generated in 2.02s and saved -> synth_data/chunk_442.txt.\n",
            "Chunk 443/1000 generated in 1.77s and saved -> synth_data/chunk_443.txt.\n",
            "Chunk 444/1000 generated in 2.07s and saved -> synth_data/chunk_444.txt.\n",
            "Chunk 445/1000 generated in 2.07s and saved -> synth_data/chunk_445.txt.\n",
            "Chunk 446/1000 generated in 1.77s and saved -> synth_data/chunk_446.txt.\n",
            "Chunk 447/1000 generated in 2.45s and saved -> synth_data/chunk_447.txt.\n",
            "Chunk 448/1000 generated in 2.15s and saved -> synth_data/chunk_448.txt.\n",
            "Chunk 449/1000 generated in 1.57s and saved -> synth_data/chunk_449.txt.\n",
            "Chunk 450/1000 generated in 1.79s and saved -> synth_data/chunk_450.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 451/1000 generated in 2.10s and saved -> synth_data/chunk_451.txt.\n",
            "Chunk 452/1000 generated in 2.07s and saved -> synth_data/chunk_452.txt.\n",
            "Chunk 453/1000 generated in 2.40s and saved -> synth_data/chunk_453.txt.\n",
            "Chunk 454/1000 generated in 2.55s and saved -> synth_data/chunk_454.txt.\n",
            "Chunk 455/1000 generated in 1.52s and saved -> synth_data/chunk_455.txt.\n",
            "Chunk 456/1000 generated in 1.87s and saved -> synth_data/chunk_456.txt.\n",
            "Chunk 457/1000 generated in 2.25s and saved -> synth_data/chunk_457.txt.\n",
            "Chunk 458/1000 generated in 1.84s and saved -> synth_data/chunk_458.txt.\n",
            "Chunk 459/1000 generated in 2.20s and saved -> synth_data/chunk_459.txt.\n",
            "Chunk 460/1000 generated in 2.10s and saved -> synth_data/chunk_460.txt.\n",
            "Chunk 461/1000 generated in 2.30s and saved -> synth_data/chunk_461.txt.\n",
            "Chunk 462/1000 generated in 2.12s and saved -> synth_data/chunk_462.txt.\n",
            "Chunk 463/1000 generated in 1.87s and saved -> synth_data/chunk_463.txt.\n",
            "Chunk 464/1000 generated in 2.70s and saved -> synth_data/chunk_464.txt.\n",
            "Chunk 465/1000 generated in 2.78s and saved -> synth_data/chunk_465.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 466/1000 generated in 2.45s and saved -> synth_data/chunk_466.txt.\n",
            "Chunk 467/1000 generated in 2.32s and saved -> synth_data/chunk_467.txt.\n",
            "Chunk 468/1000 generated in 2.15s and saved -> synth_data/chunk_468.txt.\n",
            "Chunk 469/1000 generated in 1.67s and saved -> synth_data/chunk_469.txt.\n",
            "Chunk 470/1000 generated in 2.02s and saved -> synth_data/chunk_470.txt.\n",
            "Chunk 471/1000 generated in 1.92s and saved -> synth_data/chunk_471.txt.\n",
            "Chunk 472/1000 generated in 2.32s and saved -> synth_data/chunk_472.txt.\n",
            "Chunk 473/1000 generated in 1.69s and saved -> synth_data/chunk_473.txt.\n",
            "Chunk 474/1000 generated in 1.89s and saved -> synth_data/chunk_474.txt.\n",
            "Chunk 475/1000 generated in 2.17s and saved -> synth_data/chunk_475.txt.\n",
            "Chunk 476/1000 generated in 2.55s and saved -> synth_data/chunk_476.txt.\n",
            "Chunk 477/1000 generated in 1.89s and saved -> synth_data/chunk_477.txt.\n",
            "Chunk 478/1000 generated in 1.77s and saved -> synth_data/chunk_478.txt.\n",
            "Chunk 479/1000 generated in 1.49s and saved -> synth_data/chunk_479.txt.\n",
            "Chunk 480/1000 generated in 1.90s and saved -> synth_data/chunk_480.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 481/1000 generated in 2.32s and saved -> synth_data/chunk_481.txt.\n",
            "Chunk 482/1000 generated in 2.40s and saved -> synth_data/chunk_482.txt.\n",
            "Chunk 483/1000 generated in 2.40s and saved -> synth_data/chunk_483.txt.\n",
            "Chunk 484/1000 generated in 2.15s and saved -> synth_data/chunk_484.txt.\n",
            "Chunk 485/1000 generated in 2.25s and saved -> synth_data/chunk_485.txt.\n",
            "Chunk 486/1000 generated in 1.87s and saved -> synth_data/chunk_486.txt.\n",
            "Chunk 487/1000 generated in 2.00s and saved -> synth_data/chunk_487.txt.\n",
            "Chunk 488/1000 generated in 2.58s and saved -> synth_data/chunk_488.txt.\n",
            "Chunk 489/1000 generated in 1.87s and saved -> synth_data/chunk_489.txt.\n",
            "Chunk 490/1000 generated in 2.50s and saved -> synth_data/chunk_490.txt.\n",
            "Chunk 491/1000 generated in 2.35s and saved -> synth_data/chunk_491.txt.\n",
            "Chunk 492/1000 generated in 2.07s and saved -> synth_data/chunk_492.txt.\n",
            "Chunk 493/1000 generated in 2.10s and saved -> synth_data/chunk_493.txt.\n",
            "Chunk 494/1000 generated in 2.12s and saved -> synth_data/chunk_494.txt.\n",
            "Chunk 495/1000 generated in 2.63s and saved -> synth_data/chunk_495.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 496/1000 generated in 2.40s and saved -> synth_data/chunk_496.txt.\n",
            "Chunk 497/1000 generated in 2.27s and saved -> synth_data/chunk_497.txt.\n",
            "Chunk 498/1000 generated in 2.25s and saved -> synth_data/chunk_498.txt.\n",
            "Chunk 499/1000 generated in 2.17s and saved -> synth_data/chunk_499.txt.\n",
            "Chunk 500/1000 generated in 1.97s and saved -> synth_data/chunk_500.txt.\n",
            "Chunk 501/1000 generated in 2.12s and saved -> synth_data/chunk_501.txt.\n",
            "Chunk 502/1000 generated in 1.97s and saved -> synth_data/chunk_502.txt.\n",
            "Chunk 503/1000 generated in 2.04s and saved -> synth_data/chunk_503.txt.\n",
            "Chunk 504/1000 generated in 2.10s and saved -> synth_data/chunk_504.txt.\n",
            "Chunk 505/1000 generated in 2.00s and saved -> synth_data/chunk_505.txt.\n",
            "Chunk 506/1000 generated in 1.97s and saved -> synth_data/chunk_506.txt.\n",
            "Chunk 507/1000 generated in 1.97s and saved -> synth_data/chunk_507.txt.\n",
            "Chunk 508/1000 generated in 1.79s and saved -> synth_data/chunk_508.txt.\n",
            "Chunk 509/1000 generated in 1.72s and saved -> synth_data/chunk_509.txt.\n",
            "Chunk 510/1000 generated in 2.10s and saved -> synth_data/chunk_510.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 511/1000 generated in 2.05s and saved -> synth_data/chunk_511.txt.\n",
            "Chunk 512/1000 generated in 2.27s and saved -> synth_data/chunk_512.txt.\n",
            "Chunk 513/1000 generated in 2.07s and saved -> synth_data/chunk_513.txt.\n",
            "Chunk 514/1000 generated in 2.17s and saved -> synth_data/chunk_514.txt.\n",
            "Chunk 515/1000 generated in 2.12s and saved -> synth_data/chunk_515.txt.\n",
            "Chunk 516/1000 generated in 2.12s and saved -> synth_data/chunk_516.txt.\n",
            "Chunk 517/1000 generated in 2.52s and saved -> synth_data/chunk_517.txt.\n",
            "Chunk 518/1000 generated in 1.94s and saved -> synth_data/chunk_518.txt.\n",
            "Chunk 519/1000 generated in 1.89s and saved -> synth_data/chunk_519.txt.\n",
            "Chunk 520/1000 generated in 2.62s and saved -> synth_data/chunk_520.txt.\n",
            "Chunk 521/1000 generated in 1.77s and saved -> synth_data/chunk_521.txt.\n",
            "Chunk 522/1000 generated in 1.92s and saved -> synth_data/chunk_522.txt.\n",
            "Chunk 523/1000 generated in 2.17s and saved -> synth_data/chunk_523.txt.\n",
            "Chunk 524/1000 generated in 2.17s and saved -> synth_data/chunk_524.txt.\n",
            "Chunk 525/1000 generated in 2.30s and saved -> synth_data/chunk_525.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 526/1000 generated in 2.50s and saved -> synth_data/chunk_526.txt.\n",
            "Chunk 527/1000 generated in 2.50s and saved -> synth_data/chunk_527.txt.\n",
            "Chunk 528/1000 generated in 1.77s and saved -> synth_data/chunk_528.txt.\n",
            "Chunk 529/1000 generated in 2.35s and saved -> synth_data/chunk_529.txt.\n",
            "Chunk 530/1000 generated in 2.12s and saved -> synth_data/chunk_530.txt.\n",
            "Chunk 531/1000 generated in 2.10s and saved -> synth_data/chunk_531.txt.\n",
            "Chunk 532/1000 generated in 2.00s and saved -> synth_data/chunk_532.txt.\n",
            "Chunk 533/1000 generated in 2.30s and saved -> synth_data/chunk_533.txt.\n",
            "Chunk 534/1000 generated in 1.99s and saved -> synth_data/chunk_534.txt.\n",
            "Chunk 535/1000 generated in 2.12s and saved -> synth_data/chunk_535.txt.\n",
            "Chunk 536/1000 generated in 2.35s and saved -> synth_data/chunk_536.txt.\n",
            "Chunk 537/1000 generated in 1.84s and saved -> synth_data/chunk_537.txt.\n",
            "Chunk 538/1000 generated in 2.20s and saved -> synth_data/chunk_538.txt.\n",
            "Chunk 539/1000 generated in 2.27s and saved -> synth_data/chunk_539.txt.\n",
            "Chunk 540/1000 generated in 1.77s and saved -> synth_data/chunk_540.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 541/1000 generated in 1.64s and saved -> synth_data/chunk_541.txt.\n",
            "Chunk 542/1000 generated in 1.77s and saved -> synth_data/chunk_542.txt.\n",
            "Chunk 543/1000 generated in 2.15s and saved -> synth_data/chunk_543.txt.\n",
            "Chunk 544/1000 generated in 2.02s and saved -> synth_data/chunk_544.txt.\n",
            "Chunk 545/1000 generated in 2.22s and saved -> synth_data/chunk_545.txt.\n",
            "Chunk 546/1000 generated in 2.53s and saved -> synth_data/chunk_546.txt.\n",
            "Chunk 547/1000 generated in 2.07s and saved -> synth_data/chunk_547.txt.\n",
            "Chunk 548/1000 generated in 2.12s and saved -> synth_data/chunk_548.txt.\n",
            "Chunk 549/1000 generated in 1.94s and saved -> synth_data/chunk_549.txt.\n",
            "Chunk 550/1000 generated in 2.47s and saved -> synth_data/chunk_550.txt.\n",
            "Chunk 551/1000 generated in 2.07s and saved -> synth_data/chunk_551.txt.\n",
            "Chunk 552/1000 generated in 2.14s and saved -> synth_data/chunk_552.txt.\n",
            "Chunk 553/1000 generated in 1.69s and saved -> synth_data/chunk_553.txt.\n",
            "Chunk 554/1000 generated in 2.45s and saved -> synth_data/chunk_554.txt.\n",
            "Chunk 555/1000 generated in 1.72s and saved -> synth_data/chunk_555.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 556/1000 generated in 2.73s and saved -> synth_data/chunk_556.txt.\n",
            "Chunk 557/1000 generated in 2.48s and saved -> synth_data/chunk_557.txt.\n",
            "Chunk 558/1000 generated in 1.26s and saved -> synth_data/chunk_558.txt.\n",
            "Chunk 559/1000 generated in 1.67s and saved -> synth_data/chunk_559.txt.\n",
            "Chunk 560/1000 generated in 2.60s and saved -> synth_data/chunk_560.txt.\n",
            "Chunk 561/1000 generated in 2.20s and saved -> synth_data/chunk_561.txt.\n",
            "Chunk 562/1000 generated in 1.74s and saved -> synth_data/chunk_562.txt.\n",
            "Chunk 563/1000 generated in 2.17s and saved -> synth_data/chunk_563.txt.\n",
            "Chunk 564/1000 generated in 2.22s and saved -> synth_data/chunk_564.txt.\n",
            "Chunk 565/1000 generated in 2.12s and saved -> synth_data/chunk_565.txt.\n",
            "Chunk 566/1000 generated in 1.90s and saved -> synth_data/chunk_566.txt.\n",
            "Chunk 567/1000 generated in 1.92s and saved -> synth_data/chunk_567.txt.\n",
            "Chunk 568/1000 generated in 2.17s and saved -> synth_data/chunk_568.txt.\n",
            "Chunk 569/1000 generated in 2.20s and saved -> synth_data/chunk_569.txt.\n",
            "Chunk 570/1000 generated in 2.25s and saved -> synth_data/chunk_570.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 571/1000 generated in 2.22s and saved -> synth_data/chunk_571.txt.\n",
            "Chunk 572/1000 generated in 2.22s and saved -> synth_data/chunk_572.txt.\n",
            "Chunk 573/1000 generated in 2.45s and saved -> synth_data/chunk_573.txt.\n",
            "Chunk 574/1000 generated in 1.82s and saved -> synth_data/chunk_574.txt.\n",
            "Chunk 575/1000 generated in 2.30s and saved -> synth_data/chunk_575.txt.\n",
            "Chunk 576/1000 generated in 1.95s and saved -> synth_data/chunk_576.txt.\n",
            "Chunk 577/1000 generated in 1.72s and saved -> synth_data/chunk_577.txt.\n",
            "Chunk 578/1000 generated in 1.34s and saved -> synth_data/chunk_578.txt.\n",
            "Chunk 579/1000 generated in 2.02s and saved -> synth_data/chunk_579.txt.\n",
            "Chunk 580/1000 generated in 1.82s and saved -> synth_data/chunk_580.txt.\n",
            "Chunk 581/1000 generated in 2.05s and saved -> synth_data/chunk_581.txt.\n",
            "Chunk 582/1000 generated in 1.87s and saved -> synth_data/chunk_582.txt.\n",
            "Chunk 583/1000 generated in 1.90s and saved -> synth_data/chunk_583.txt.\n",
            "Chunk 584/1000 generated in 1.94s and saved -> synth_data/chunk_584.txt.\n",
            "Chunk 585/1000 generated in 2.37s and saved -> synth_data/chunk_585.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 586/1000 generated in 2.12s and saved -> synth_data/chunk_586.txt.\n",
            "Chunk 587/1000 generated in 1.79s and saved -> synth_data/chunk_587.txt.\n",
            "Chunk 588/1000 generated in 1.87s and saved -> synth_data/chunk_588.txt.\n",
            "Chunk 589/1000 generated in 2.83s and saved -> synth_data/chunk_589.txt.\n",
            "Chunk 590/1000 generated in 1.84s and saved -> synth_data/chunk_590.txt.\n",
            "Chunk 591/1000 generated in 2.12s and saved -> synth_data/chunk_591.txt.\n",
            "Chunk 592/1000 generated in 2.72s and saved -> synth_data/chunk_592.txt.\n",
            "Chunk 593/1000 generated in 2.32s and saved -> synth_data/chunk_593.txt.\n",
            "Chunk 594/1000 generated in 2.27s and saved -> synth_data/chunk_594.txt.\n",
            "Chunk 595/1000 generated in 2.57s and saved -> synth_data/chunk_595.txt.\n",
            "Chunk 596/1000 generated in 1.77s and saved -> synth_data/chunk_596.txt.\n",
            "Chunk 597/1000 generated in 2.45s and saved -> synth_data/chunk_597.txt.\n",
            "Chunk 598/1000 generated in 1.95s and saved -> synth_data/chunk_598.txt.\n",
            "Chunk 599/1000 generated in 1.74s and saved -> synth_data/chunk_599.txt.\n",
            "Chunk 600/1000 generated in 1.77s and saved -> synth_data/chunk_600.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 601/1000 generated in 2.00s and saved -> synth_data/chunk_601.txt.\n",
            "Chunk 602/1000 generated in 2.12s and saved -> synth_data/chunk_602.txt.\n",
            "Chunk 603/1000 generated in 1.69s and saved -> synth_data/chunk_603.txt.\n",
            "Chunk 604/1000 generated in 1.79s and saved -> synth_data/chunk_604.txt.\n",
            "Chunk 605/1000 generated in 2.02s and saved -> synth_data/chunk_605.txt.\n",
            "Chunk 606/1000 generated in 1.79s and saved -> synth_data/chunk_606.txt.\n",
            "Chunk 607/1000 generated in 1.69s and saved -> synth_data/chunk_607.txt.\n",
            "Chunk 608/1000 generated in 2.60s and saved -> synth_data/chunk_608.txt.\n",
            "Chunk 609/1000 generated in 2.40s and saved -> synth_data/chunk_609.txt.\n",
            "Chunk 610/1000 generated in 2.02s and saved -> synth_data/chunk_610.txt.\n",
            "Chunk 611/1000 generated in 2.68s and saved -> synth_data/chunk_611.txt.\n",
            "Chunk 612/1000 generated in 2.50s and saved -> synth_data/chunk_612.txt.\n",
            "Chunk 613/1000 generated in 2.05s and saved -> synth_data/chunk_613.txt.\n",
            "Chunk 614/1000 generated in 2.55s and saved -> synth_data/chunk_614.txt.\n",
            "Chunk 615/1000 generated in 1.69s and saved -> synth_data/chunk_615.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 616/1000 generated in 2.71s and saved -> synth_data/chunk_616.txt.\n",
            "Chunk 617/1000 generated in 2.27s and saved -> synth_data/chunk_617.txt.\n",
            "Chunk 618/1000 generated in 1.90s and saved -> synth_data/chunk_618.txt.\n",
            "Chunk 619/1000 generated in 1.87s and saved -> synth_data/chunk_619.txt.\n",
            "Chunk 620/1000 generated in 2.12s and saved -> synth_data/chunk_620.txt.\n",
            "Chunk 621/1000 generated in 2.07s and saved -> synth_data/chunk_621.txt.\n",
            "Chunk 622/1000 generated in 1.77s and saved -> synth_data/chunk_622.txt.\n",
            "Chunk 623/1000 generated in 2.48s and saved -> synth_data/chunk_623.txt.\n",
            "Chunk 624/1000 generated in 1.44s and saved -> synth_data/chunk_624.txt.\n",
            "Chunk 625/1000 generated in 1.90s and saved -> synth_data/chunk_625.txt.\n",
            "Chunk 626/1000 generated in 2.17s and saved -> synth_data/chunk_626.txt.\n",
            "Chunk 627/1000 generated in 2.30s and saved -> synth_data/chunk_627.txt.\n",
            "Chunk 628/1000 generated in 1.80s and saved -> synth_data/chunk_628.txt.\n",
            "Chunk 629/1000 generated in 1.62s and saved -> synth_data/chunk_629.txt.\n",
            "Chunk 630/1000 generated in 1.85s and saved -> synth_data/chunk_630.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 631/1000 generated in 1.70s and saved -> synth_data/chunk_631.txt.\n",
            "Chunk 632/1000 generated in 2.20s and saved -> synth_data/chunk_632.txt.\n",
            "Chunk 633/1000 generated in 1.39s and saved -> synth_data/chunk_633.txt.\n",
            "Chunk 634/1000 generated in 2.27s and saved -> synth_data/chunk_634.txt.\n",
            "Chunk 635/1000 generated in 2.53s and saved -> synth_data/chunk_635.txt.\n",
            "Chunk 636/1000 generated in 2.28s and saved -> synth_data/chunk_636.txt.\n",
            "Chunk 637/1000 generated in 2.21s and saved -> synth_data/chunk_637.txt.\n",
            "Chunk 638/1000 generated in 2.00s and saved -> synth_data/chunk_638.txt.\n",
            "Chunk 639/1000 generated in 2.31s and saved -> synth_data/chunk_639.txt.\n",
            "Chunk 640/1000 generated in 1.47s and saved -> synth_data/chunk_640.txt.\n",
            "Chunk 641/1000 generated in 2.45s and saved -> synth_data/chunk_641.txt.\n",
            "Chunk 642/1000 generated in 2.10s and saved -> synth_data/chunk_642.txt.\n",
            "Chunk 643/1000 generated in 2.00s and saved -> synth_data/chunk_643.txt.\n",
            "Chunk 644/1000 generated in 2.00s and saved -> synth_data/chunk_644.txt.\n",
            "Chunk 645/1000 generated in 2.18s and saved -> synth_data/chunk_645.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 646/1000 generated in 2.00s and saved -> synth_data/chunk_646.txt.\n",
            "Chunk 647/1000 generated in 1.75s and saved -> synth_data/chunk_647.txt.\n",
            "Chunk 648/1000 generated in 2.00s and saved -> synth_data/chunk_648.txt.\n",
            "Chunk 649/1000 generated in 1.65s and saved -> synth_data/chunk_649.txt.\n",
            "Chunk 650/1000 generated in 1.57s and saved -> synth_data/chunk_650.txt.\n",
            "Chunk 651/1000 generated in 1.97s and saved -> synth_data/chunk_651.txt.\n",
            "Chunk 652/1000 generated in 2.50s and saved -> synth_data/chunk_652.txt.\n",
            "Chunk 653/1000 generated in 1.95s and saved -> synth_data/chunk_653.txt.\n",
            "Chunk 654/1000 generated in 2.48s and saved -> synth_data/chunk_654.txt.\n",
            "Chunk 655/1000 generated in 2.02s and saved -> synth_data/chunk_655.txt.\n",
            "Chunk 656/1000 generated in 1.74s and saved -> synth_data/chunk_656.txt.\n",
            "Chunk 657/1000 generated in 2.00s and saved -> synth_data/chunk_657.txt.\n",
            "Chunk 658/1000 generated in 2.10s and saved -> synth_data/chunk_658.txt.\n",
            "Chunk 659/1000 generated in 2.55s and saved -> synth_data/chunk_659.txt.\n",
            "Chunk 660/1000 generated in 1.85s and saved -> synth_data/chunk_660.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 661/1000 generated in 2.23s and saved -> synth_data/chunk_661.txt.\n",
            "Chunk 662/1000 generated in 1.29s and saved -> synth_data/chunk_662.txt.\n",
            "Chunk 663/1000 generated in 1.92s and saved -> synth_data/chunk_663.txt.\n",
            "Chunk 664/1000 generated in 2.03s and saved -> synth_data/chunk_664.txt.\n",
            "Chunk 665/1000 generated in 2.25s and saved -> synth_data/chunk_665.txt.\n",
            "Chunk 666/1000 generated in 1.82s and saved -> synth_data/chunk_666.txt.\n",
            "Chunk 667/1000 generated in 1.97s and saved -> synth_data/chunk_667.txt.\n",
            "Chunk 668/1000 generated in 2.53s and saved -> synth_data/chunk_668.txt.\n",
            "Chunk 669/1000 generated in 2.00s and saved -> synth_data/chunk_669.txt.\n",
            "Chunk 670/1000 generated in 1.95s and saved -> synth_data/chunk_670.txt.\n",
            "Chunk 671/1000 generated in 2.48s and saved -> synth_data/chunk_671.txt.\n",
            "Chunk 672/1000 generated in 1.87s and saved -> synth_data/chunk_672.txt.\n",
            "Chunk 673/1000 generated in 1.90s and saved -> synth_data/chunk_673.txt.\n",
            "Chunk 674/1000 generated in 2.00s and saved -> synth_data/chunk_674.txt.\n",
            "Chunk 675/1000 generated in 2.02s and saved -> synth_data/chunk_675.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 676/1000 generated in 1.87s and saved -> synth_data/chunk_676.txt.\n",
            "Chunk 677/1000 generated in 2.20s and saved -> synth_data/chunk_677.txt.\n",
            "Chunk 678/1000 generated in 1.82s and saved -> synth_data/chunk_678.txt.\n",
            "Chunk 679/1000 generated in 1.97s and saved -> synth_data/chunk_679.txt.\n",
            "Chunk 680/1000 generated in 2.30s and saved -> synth_data/chunk_680.txt.\n",
            "Chunk 681/1000 generated in 2.15s and saved -> synth_data/chunk_681.txt.\n",
            "Chunk 682/1000 generated in 2.12s and saved -> synth_data/chunk_682.txt.\n",
            "Chunk 683/1000 generated in 2.12s and saved -> synth_data/chunk_683.txt.\n",
            "Chunk 684/1000 generated in 2.07s and saved -> synth_data/chunk_684.txt.\n",
            "Chunk 685/1000 generated in 1.95s and saved -> synth_data/chunk_685.txt.\n",
            "Chunk 686/1000 generated in 2.27s and saved -> synth_data/chunk_686.txt.\n",
            "Chunk 687/1000 generated in 1.67s and saved -> synth_data/chunk_687.txt.\n",
            "Chunk 688/1000 generated in 2.15s and saved -> synth_data/chunk_688.txt.\n",
            "Chunk 689/1000 generated in 2.25s and saved -> synth_data/chunk_689.txt.\n",
            "Chunk 690/1000 generated in 1.52s and saved -> synth_data/chunk_690.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 691/1000 generated in 2.55s and saved -> synth_data/chunk_691.txt.\n",
            "Chunk 692/1000 generated in 2.27s and saved -> synth_data/chunk_692.txt.\n",
            "Chunk 693/1000 generated in 2.28s and saved -> synth_data/chunk_693.txt.\n",
            "Chunk 694/1000 generated in 1.77s and saved -> synth_data/chunk_694.txt.\n",
            "Chunk 695/1000 generated in 2.48s and saved -> synth_data/chunk_695.txt.\n",
            "Chunk 696/1000 generated in 2.25s and saved -> synth_data/chunk_696.txt.\n",
            "Chunk 697/1000 generated in 2.18s and saved -> synth_data/chunk_697.txt.\n",
            "Chunk 698/1000 generated in 2.50s and saved -> synth_data/chunk_698.txt.\n",
            "Chunk 699/1000 generated in 2.50s and saved -> synth_data/chunk_699.txt.\n",
            "Chunk 700/1000 generated in 2.33s and saved -> synth_data/chunk_700.txt.\n",
            "Chunk 701/1000 generated in 2.23s and saved -> synth_data/chunk_701.txt.\n",
            "Chunk 702/1000 generated in 1.90s and saved -> synth_data/chunk_702.txt.\n",
            "Chunk 703/1000 generated in 2.30s and saved -> synth_data/chunk_703.txt.\n",
            "Chunk 704/1000 generated in 2.20s and saved -> synth_data/chunk_704.txt.\n",
            "Chunk 705/1000 generated in 2.25s and saved -> synth_data/chunk_705.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 706/1000 generated in 2.46s and saved -> synth_data/chunk_706.txt.\n",
            "Chunk 707/1000 generated in 1.60s and saved -> synth_data/chunk_707.txt.\n",
            "Chunk 708/1000 generated in 2.60s and saved -> synth_data/chunk_708.txt.\n",
            "Chunk 709/1000 generated in 2.05s and saved -> synth_data/chunk_709.txt.\n",
            "Chunk 710/1000 generated in 1.44s and saved -> synth_data/chunk_710.txt.\n",
            "Chunk 711/1000 generated in 2.13s and saved -> synth_data/chunk_711.txt.\n",
            "Chunk 712/1000 generated in 1.87s and saved -> synth_data/chunk_712.txt.\n",
            "Chunk 713/1000 generated in 2.10s and saved -> synth_data/chunk_713.txt.\n",
            "Chunk 714/1000 generated in 1.77s and saved -> synth_data/chunk_714.txt.\n",
            "Chunk 715/1000 generated in 2.05s and saved -> synth_data/chunk_715.txt.\n",
            "Chunk 716/1000 generated in 1.62s and saved -> synth_data/chunk_716.txt.\n",
            "Chunk 717/1000 generated in 2.00s and saved -> synth_data/chunk_717.txt.\n",
            "Chunk 718/1000 generated in 2.22s and saved -> synth_data/chunk_718.txt.\n",
            "Chunk 719/1000 generated in 2.32s and saved -> synth_data/chunk_719.txt.\n",
            "Chunk 720/1000 generated in 2.28s and saved -> synth_data/chunk_720.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 721/1000 generated in 2.45s and saved -> synth_data/chunk_721.txt.\n",
            "Chunk 722/1000 generated in 2.00s and saved -> synth_data/chunk_722.txt.\n",
            "Chunk 723/1000 generated in 2.20s and saved -> synth_data/chunk_723.txt.\n",
            "Chunk 724/1000 generated in 2.33s and saved -> synth_data/chunk_724.txt.\n",
            "Chunk 725/1000 generated in 1.92s and saved -> synth_data/chunk_725.txt.\n",
            "Chunk 726/1000 generated in 1.90s and saved -> synth_data/chunk_726.txt.\n",
            "Chunk 727/1000 generated in 2.37s and saved -> synth_data/chunk_727.txt.\n",
            "Chunk 728/1000 generated in 1.74s and saved -> synth_data/chunk_728.txt.\n",
            "Chunk 729/1000 generated in 1.87s and saved -> synth_data/chunk_729.txt.\n",
            "Chunk 730/1000 generated in 2.17s and saved -> synth_data/chunk_730.txt.\n",
            "Chunk 731/1000 generated in 1.97s and saved -> synth_data/chunk_731.txt.\n",
            "Chunk 732/1000 generated in 1.54s and saved -> synth_data/chunk_732.txt.\n",
            "Chunk 733/1000 generated in 2.15s and saved -> synth_data/chunk_733.txt.\n",
            "Chunk 734/1000 generated in 1.95s and saved -> synth_data/chunk_734.txt.\n",
            "Chunk 735/1000 generated in 2.08s and saved -> synth_data/chunk_735.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 736/1000 generated in 2.23s and saved -> synth_data/chunk_736.txt.\n",
            "Chunk 737/1000 generated in 1.95s and saved -> synth_data/chunk_737.txt.\n",
            "Chunk 738/1000 generated in 1.95s and saved -> synth_data/chunk_738.txt.\n",
            "Chunk 739/1000 generated in 2.25s and saved -> synth_data/chunk_739.txt.\n",
            "Chunk 740/1000 generated in 2.00s and saved -> synth_data/chunk_740.txt.\n",
            "Chunk 741/1000 generated in 2.05s and saved -> synth_data/chunk_741.txt.\n",
            "Chunk 742/1000 generated in 2.25s and saved -> synth_data/chunk_742.txt.\n",
            "Chunk 743/1000 generated in 2.51s and saved -> synth_data/chunk_743.txt.\n",
            "Chunk 744/1000 generated in 2.02s and saved -> synth_data/chunk_744.txt.\n",
            "Chunk 745/1000 generated in 1.97s and saved -> synth_data/chunk_745.txt.\n",
            "Chunk 746/1000 generated in 2.45s and saved -> synth_data/chunk_746.txt.\n",
            "Chunk 747/1000 generated in 1.67s and saved -> synth_data/chunk_747.txt.\n",
            "Chunk 748/1000 generated in 2.07s and saved -> synth_data/chunk_748.txt.\n",
            "Chunk 749/1000 generated in 1.82s and saved -> synth_data/chunk_749.txt.\n",
            "Chunk 750/1000 generated in 2.13s and saved -> synth_data/chunk_750.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 751/1000 generated in 1.77s and saved -> synth_data/chunk_751.txt.\n",
            "Chunk 752/1000 generated in 2.20s and saved -> synth_data/chunk_752.txt.\n",
            "Chunk 753/1000 generated in 2.00s and saved -> synth_data/chunk_753.txt.\n",
            "Chunk 754/1000 generated in 2.08s and saved -> synth_data/chunk_754.txt.\n",
            "Chunk 755/1000 generated in 2.10s and saved -> synth_data/chunk_755.txt.\n",
            "Chunk 756/1000 generated in 2.12s and saved -> synth_data/chunk_756.txt.\n",
            "Chunk 757/1000 generated in 2.07s and saved -> synth_data/chunk_757.txt.\n",
            "Chunk 758/1000 generated in 2.05s and saved -> synth_data/chunk_758.txt.\n",
            "Chunk 759/1000 generated in 1.75s and saved -> synth_data/chunk_759.txt.\n",
            "Chunk 760/1000 generated in 1.74s and saved -> synth_data/chunk_760.txt.\n",
            "Chunk 761/1000 generated in 3.08s and saved -> synth_data/chunk_761.txt.\n",
            "Chunk 762/1000 generated in 2.17s and saved -> synth_data/chunk_762.txt.\n",
            "Chunk 763/1000 generated in 2.25s and saved -> synth_data/chunk_763.txt.\n",
            "Chunk 764/1000 generated in 1.54s and saved -> synth_data/chunk_764.txt.\n",
            "Chunk 765/1000 generated in 2.22s and saved -> synth_data/chunk_765.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 766/1000 generated in 2.60s and saved -> synth_data/chunk_766.txt.\n",
            "Chunk 767/1000 generated in 2.30s and saved -> synth_data/chunk_767.txt.\n",
            "Chunk 768/1000 generated in 2.15s and saved -> synth_data/chunk_768.txt.\n",
            "Chunk 769/1000 generated in 2.28s and saved -> synth_data/chunk_769.txt.\n",
            "Chunk 770/1000 generated in 2.35s and saved -> synth_data/chunk_770.txt.\n",
            "Chunk 771/1000 generated in 2.48s and saved -> synth_data/chunk_771.txt.\n",
            "Chunk 772/1000 generated in 2.38s and saved -> synth_data/chunk_772.txt.\n",
            "Chunk 773/1000 generated in 2.18s and saved -> synth_data/chunk_773.txt.\n",
            "Chunk 774/1000 generated in 3.23s and saved -> synth_data/chunk_774.txt.\n",
            "Chunk 775/1000 generated in 2.60s and saved -> synth_data/chunk_775.txt.\n",
            "Chunk 776/1000 generated in 2.48s and saved -> synth_data/chunk_776.txt.\n",
            "Chunk 777/1000 generated in 1.62s and saved -> synth_data/chunk_777.txt.\n",
            "Chunk 778/1000 generated in 1.87s and saved -> synth_data/chunk_778.txt.\n",
            "Chunk 779/1000 generated in 2.40s and saved -> synth_data/chunk_779.txt.\n",
            "Chunk 780/1000 generated in 2.00s and saved -> synth_data/chunk_780.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 781/1000 generated in 2.48s and saved -> synth_data/chunk_781.txt.\n",
            "Chunk 782/1000 generated in 2.43s and saved -> synth_data/chunk_782.txt.\n",
            "Chunk 783/1000 generated in 2.35s and saved -> synth_data/chunk_783.txt.\n",
            "Chunk 784/1000 generated in 2.07s and saved -> synth_data/chunk_784.txt.\n",
            "Chunk 785/1000 generated in 2.50s and saved -> synth_data/chunk_785.txt.\n",
            "Chunk 786/1000 generated in 1.80s and saved -> synth_data/chunk_786.txt.\n",
            "Chunk 787/1000 generated in 2.08s and saved -> synth_data/chunk_787.txt.\n",
            "Chunk 788/1000 generated in 2.25s and saved -> synth_data/chunk_788.txt.\n",
            "Chunk 789/1000 generated in 2.47s and saved -> synth_data/chunk_789.txt.\n",
            "Chunk 790/1000 generated in 1.74s and saved -> synth_data/chunk_790.txt.\n",
            "Chunk 791/1000 generated in 2.07s and saved -> synth_data/chunk_791.txt.\n",
            "Chunk 792/1000 generated in 1.85s and saved -> synth_data/chunk_792.txt.\n",
            "Chunk 793/1000 generated in 1.97s and saved -> synth_data/chunk_793.txt.\n",
            "Chunk 794/1000 generated in 2.70s and saved -> synth_data/chunk_794.txt.\n",
            "Chunk 795/1000 generated in 2.30s and saved -> synth_data/chunk_795.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 796/1000 generated in 1.97s and saved -> synth_data/chunk_796.txt.\n",
            "Chunk 797/1000 generated in 2.05s and saved -> synth_data/chunk_797.txt.\n",
            "Chunk 798/1000 generated in 2.10s and saved -> synth_data/chunk_798.txt.\n",
            "Chunk 799/1000 generated in 2.20s and saved -> synth_data/chunk_799.txt.\n",
            "Chunk 800/1000 generated in 2.15s and saved -> synth_data/chunk_800.txt.\n",
            "Chunk 801/1000 generated in 2.55s and saved -> synth_data/chunk_801.txt.\n",
            "Chunk 802/1000 generated in 2.93s and saved -> synth_data/chunk_802.txt.\n",
            "Chunk 803/1000 generated in 2.58s and saved -> synth_data/chunk_803.txt.\n",
            "Chunk 804/1000 generated in 2.07s and saved -> synth_data/chunk_804.txt.\n",
            "Chunk 805/1000 generated in 2.02s and saved -> synth_data/chunk_805.txt.\n",
            "Chunk 806/1000 generated in 2.40s and saved -> synth_data/chunk_806.txt.\n",
            "Chunk 807/1000 generated in 2.40s and saved -> synth_data/chunk_807.txt.\n",
            "Chunk 808/1000 generated in 1.82s and saved -> synth_data/chunk_808.txt.\n",
            "Chunk 809/1000 generated in 2.15s and saved -> synth_data/chunk_809.txt.\n",
            "Chunk 810/1000 generated in 1.62s and saved -> synth_data/chunk_810.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 811/1000 generated in 2.23s and saved -> synth_data/chunk_811.txt.\n",
            "Chunk 812/1000 generated in 2.02s and saved -> synth_data/chunk_812.txt.\n",
            "Chunk 813/1000 generated in 1.87s and saved -> synth_data/chunk_813.txt.\n",
            "Chunk 814/1000 generated in 1.92s and saved -> synth_data/chunk_814.txt.\n",
            "Chunk 815/1000 generated in 2.15s and saved -> synth_data/chunk_815.txt.\n",
            "Chunk 816/1000 generated in 1.64s and saved -> synth_data/chunk_816.txt.\n",
            "Chunk 817/1000 generated in 2.12s and saved -> synth_data/chunk_817.txt.\n",
            "Chunk 818/1000 generated in 2.07s and saved -> synth_data/chunk_818.txt.\n",
            "Chunk 819/1000 generated in 2.40s and saved -> synth_data/chunk_819.txt.\n",
            "Chunk 820/1000 generated in 1.64s and saved -> synth_data/chunk_820.txt.\n",
            "An error occurred while processing Chunk 821: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
            "Chunk 822/1000 generated in 2.23s and saved -> synth_data/chunk_822.txt.\n",
            "Chunk 823/1000 generated in 2.33s and saved -> synth_data/chunk_823.txt.\n",
            "Chunk 824/1000 generated in 2.55s and saved -> synth_data/chunk_824.txt.\n",
            "Chunk 825/1000 generated in 2.47s and saved -> synth_data/chunk_825.txt.\n",
            "Chunk 826/1000 generated in 2.10s and saved -> synth_data/chunk_826.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 827/1000 generated in 2.35s and saved -> synth_data/chunk_827.txt.\n",
            "Chunk 828/1000 generated in 1.97s and saved -> synth_data/chunk_828.txt.\n",
            "Chunk 829/1000 generated in 1.95s and saved -> synth_data/chunk_829.txt.\n",
            "An error occurred while processing Chunk 830: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
            "Chunk 831/1000 generated in 1.87s and saved -> synth_data/chunk_831.txt.\n",
            "Chunk 832/1000 generated in 2.37s and saved -> synth_data/chunk_832.txt.\n",
            "Chunk 833/1000 generated in 2.38s and saved -> synth_data/chunk_833.txt.\n",
            "Chunk 834/1000 generated in 2.35s and saved -> synth_data/chunk_834.txt.\n",
            "Chunk 835/1000 generated in 2.00s and saved -> synth_data/chunk_835.txt.\n",
            "Chunk 836/1000 generated in 2.17s and saved -> synth_data/chunk_836.txt.\n",
            "Chunk 837/1000 generated in 1.92s and saved -> synth_data/chunk_837.txt.\n",
            "Chunk 838/1000 generated in 2.10s and saved -> synth_data/chunk_838.txt.\n",
            "Chunk 839/1000 generated in 2.57s and saved -> synth_data/chunk_839.txt.\n",
            "Chunk 840/1000 generated in 2.00s and saved -> synth_data/chunk_840.txt.\n",
            "Chunk 841/1000 generated in 1.97s and saved -> synth_data/chunk_841.txt.\n",
            "Chunk 842/1000 generated in 2.22s and saved -> synth_data/chunk_842.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 843/1000 generated in 3.25s and saved -> synth_data/chunk_843.txt.\n",
            "Chunk 844/1000 generated in 2.30s and saved -> synth_data/chunk_844.txt.\n",
            "Chunk 845/1000 generated in 1.70s and saved -> synth_data/chunk_845.txt.\n",
            "Chunk 846/1000 generated in 1.62s and saved -> synth_data/chunk_846.txt.\n",
            "Chunk 847/1000 generated in 2.32s and saved -> synth_data/chunk_847.txt.\n",
            "Chunk 848/1000 generated in 2.73s and saved -> synth_data/chunk_848.txt.\n",
            "Chunk 849/1000 generated in 1.59s and saved -> synth_data/chunk_849.txt.\n",
            "Chunk 850/1000 generated in 2.68s and saved -> synth_data/chunk_850.txt.\n",
            "Chunk 851/1000 generated in 2.10s and saved -> synth_data/chunk_851.txt.\n",
            "Chunk 852/1000 generated in 2.48s and saved -> synth_data/chunk_852.txt.\n",
            "Chunk 853/1000 generated in 2.53s and saved -> synth_data/chunk_853.txt.\n",
            "Chunk 854/1000 generated in 2.37s and saved -> synth_data/chunk_854.txt.\n",
            "Chunk 855/1000 generated in 1.97s and saved -> synth_data/chunk_855.txt.\n",
            "Chunk 856/1000 generated in 1.72s and saved -> synth_data/chunk_856.txt.\n",
            "Chunk 857/1000 generated in 2.61s and saved -> synth_data/chunk_857.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 858/1000 generated in 1.90s and saved -> synth_data/chunk_858.txt.\n",
            "Chunk 859/1000 generated in 2.25s and saved -> synth_data/chunk_859.txt.\n",
            "Chunk 860/1000 generated in 1.72s and saved -> synth_data/chunk_860.txt.\n",
            "Chunk 861/1000 generated in 2.50s and saved -> synth_data/chunk_861.txt.\n",
            "Chunk 862/1000 generated in 2.20s and saved -> synth_data/chunk_862.txt.\n",
            "Chunk 863/1000 generated in 2.20s and saved -> synth_data/chunk_863.txt.\n",
            "Chunk 864/1000 generated in 2.10s and saved -> synth_data/chunk_864.txt.\n",
            "Chunk 865/1000 generated in 2.07s and saved -> synth_data/chunk_865.txt.\n",
            "Chunk 866/1000 generated in 1.95s and saved -> synth_data/chunk_866.txt.\n",
            "Chunk 867/1000 generated in 2.10s and saved -> synth_data/chunk_867.txt.\n",
            "Chunk 868/1000 generated in 2.32s and saved -> synth_data/chunk_868.txt.\n",
            "Chunk 869/1000 generated in 2.45s and saved -> synth_data/chunk_869.txt.\n",
            "Chunk 870/1000 generated in 2.53s and saved -> synth_data/chunk_870.txt.\n",
            "Chunk 871/1000 generated in 2.42s and saved -> synth_data/chunk_871.txt.\n",
            "Chunk 872/1000 generated in 1.92s and saved -> synth_data/chunk_872.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 873/1000 generated in 2.32s and saved -> synth_data/chunk_873.txt.\n",
            "Chunk 874/1000 generated in 1.84s and saved -> synth_data/chunk_874.txt.\n",
            "Chunk 875/1000 generated in 1.59s and saved -> synth_data/chunk_875.txt.\n",
            "Chunk 876/1000 generated in 1.95s and saved -> synth_data/chunk_876.txt.\n",
            "Chunk 877/1000 generated in 2.00s and saved -> synth_data/chunk_877.txt.\n",
            "Chunk 878/1000 generated in 2.10s and saved -> synth_data/chunk_878.txt.\n",
            "Chunk 879/1000 generated in 2.55s and saved -> synth_data/chunk_879.txt.\n",
            "Chunk 880/1000 generated in 2.10s and saved -> synth_data/chunk_880.txt.\n",
            "Chunk 881/1000 generated in 1.87s and saved -> synth_data/chunk_881.txt.\n",
            "Chunk 882/1000 generated in 2.37s and saved -> synth_data/chunk_882.txt.\n",
            "Chunk 883/1000 generated in 2.05s and saved -> synth_data/chunk_883.txt.\n",
            "Chunk 884/1000 generated in 2.40s and saved -> synth_data/chunk_884.txt.\n",
            "Chunk 885/1000 generated in 1.97s and saved -> synth_data/chunk_885.txt.\n",
            "Chunk 886/1000 generated in 2.28s and saved -> synth_data/chunk_886.txt.\n",
            "Chunk 887/1000 generated in 2.02s and saved -> synth_data/chunk_887.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 888/1000 generated in 2.12s and saved -> synth_data/chunk_888.txt.\n",
            "Chunk 889/1000 generated in 1.95s and saved -> synth_data/chunk_889.txt.\n",
            "Chunk 890/1000 generated in 1.97s and saved -> synth_data/chunk_890.txt.\n",
            "Chunk 891/1000 generated in 2.75s and saved -> synth_data/chunk_891.txt.\n",
            "Chunk 892/1000 generated in 1.82s and saved -> synth_data/chunk_892.txt.\n",
            "Chunk 893/1000 generated in 2.00s and saved -> synth_data/chunk_893.txt.\n",
            "Chunk 894/1000 generated in 2.76s and saved -> synth_data/chunk_894.txt.\n",
            "Chunk 895/1000 generated in 1.95s and saved -> synth_data/chunk_895.txt.\n",
            "Chunk 896/1000 generated in 1.69s and saved -> synth_data/chunk_896.txt.\n",
            "Chunk 897/1000 generated in 2.32s and saved -> synth_data/chunk_897.txt.\n",
            "Chunk 898/1000 generated in 2.10s and saved -> synth_data/chunk_898.txt.\n",
            "Chunk 899/1000 generated in 2.70s and saved -> synth_data/chunk_899.txt.\n",
            "Chunk 900/1000 generated in 1.92s and saved -> synth_data/chunk_900.txt.\n",
            "Chunk 901/1000 generated in 2.04s and saved -> synth_data/chunk_901.txt.\n",
            "Chunk 902/1000 generated in 1.69s and saved -> synth_data/chunk_902.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 903/1000 generated in 2.20s and saved -> synth_data/chunk_903.txt.\n",
            "Chunk 904/1000 generated in 2.15s and saved -> synth_data/chunk_904.txt.\n",
            "Chunk 905/1000 generated in 1.64s and saved -> synth_data/chunk_905.txt.\n",
            "Chunk 906/1000 generated in 2.30s and saved -> synth_data/chunk_906.txt.\n",
            "Chunk 907/1000 generated in 1.57s and saved -> synth_data/chunk_907.txt.\n",
            "Chunk 908/1000 generated in 1.82s and saved -> synth_data/chunk_908.txt.\n",
            "Chunk 909/1000 generated in 1.97s and saved -> synth_data/chunk_909.txt.\n",
            "Chunk 910/1000 generated in 2.52s and saved -> synth_data/chunk_910.txt.\n",
            "Chunk 911/1000 generated in 2.22s and saved -> synth_data/chunk_911.txt.\n",
            "Chunk 912/1000 generated in 2.45s and saved -> synth_data/chunk_912.txt.\n",
            "Chunk 913/1000 generated in 3.11s and saved -> synth_data/chunk_913.txt.\n",
            "Chunk 914/1000 generated in 2.63s and saved -> synth_data/chunk_914.txt.\n",
            "Chunk 915/1000 generated in 2.27s and saved -> synth_data/chunk_915.txt.\n",
            "Chunk 916/1000 generated in 1.97s and saved -> synth_data/chunk_916.txt.\n",
            "Chunk 917/1000 generated in 2.72s and saved -> synth_data/chunk_917.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 918/1000 generated in 2.02s and saved -> synth_data/chunk_918.txt.\n",
            "Chunk 919/1000 generated in 2.55s and saved -> synth_data/chunk_919.txt.\n",
            "Chunk 920/1000 generated in 1.67s and saved -> synth_data/chunk_920.txt.\n",
            "Chunk 921/1000 generated in 2.15s and saved -> synth_data/chunk_921.txt.\n",
            "Chunk 922/1000 generated in 2.52s and saved -> synth_data/chunk_922.txt.\n",
            "Chunk 923/1000 generated in 2.42s and saved -> synth_data/chunk_923.txt.\n",
            "Chunk 924/1000 generated in 1.82s and saved -> synth_data/chunk_924.txt.\n",
            "Chunk 925/1000 generated in 2.28s and saved -> synth_data/chunk_925.txt.\n",
            "Chunk 926/1000 generated in 2.15s and saved -> synth_data/chunk_926.txt.\n",
            "Chunk 927/1000 generated in 1.95s and saved -> synth_data/chunk_927.txt.\n",
            "Chunk 928/1000 generated in 2.68s and saved -> synth_data/chunk_928.txt.\n",
            "Chunk 929/1000 generated in 2.53s and saved -> synth_data/chunk_929.txt.\n",
            "Chunk 930/1000 generated in 2.35s and saved -> synth_data/chunk_930.txt.\n",
            "Chunk 931/1000 generated in 1.67s and saved -> synth_data/chunk_931.txt.\n",
            "Chunk 932/1000 generated in 1.79s and saved -> synth_data/chunk_932.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 933/1000 generated in 2.27s and saved -> synth_data/chunk_933.txt.\n",
            "Chunk 934/1000 generated in 2.63s and saved -> synth_data/chunk_934.txt.\n",
            "Chunk 935/1000 generated in 2.05s and saved -> synth_data/chunk_935.txt.\n",
            "Chunk 936/1000 generated in 2.22s and saved -> synth_data/chunk_936.txt.\n",
            "Chunk 937/1000 generated in 2.35s and saved -> synth_data/chunk_937.txt.\n",
            "An error occurred while processing Chunk 938: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
            "Chunk 939/1000 generated in 2.55s and saved -> synth_data/chunk_939.txt.\n",
            "Chunk 940/1000 generated in 1.94s and saved -> synth_data/chunk_940.txt.\n",
            "Chunk 941/1000 generated in 1.77s and saved -> synth_data/chunk_941.txt.\n",
            "Chunk 942/1000 generated in 1.95s and saved -> synth_data/chunk_942.txt.\n",
            "Chunk 943/1000 generated in 1.49s and saved -> synth_data/chunk_943.txt.\n",
            "Chunk 944/1000 generated in 2.15s and saved -> synth_data/chunk_944.txt.\n",
            "Chunk 945/1000 generated in 2.48s and saved -> synth_data/chunk_945.txt.\n",
            "Chunk 946/1000 generated in 1.95s and saved -> synth_data/chunk_946.txt.\n",
            "Chunk 947/1000 generated in 1.97s and saved -> synth_data/chunk_947.txt.\n",
            "Chunk 948/1000 generated in 1.87s and saved -> synth_data/chunk_948.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 949/1000 generated in 1.80s and saved -> synth_data/chunk_949.txt.\n",
            "Chunk 950/1000 generated in 1.87s and saved -> synth_data/chunk_950.txt.\n",
            "Chunk 951/1000 generated in 1.87s and saved -> synth_data/chunk_951.txt.\n",
            "Chunk 952/1000 generated in 2.68s and saved -> synth_data/chunk_952.txt.\n",
            "Chunk 953/1000 generated in 2.25s and saved -> synth_data/chunk_953.txt.\n",
            "Chunk 954/1000 generated in 2.00s and saved -> synth_data/chunk_954.txt.\n",
            "Chunk 955/1000 generated in 2.25s and saved -> synth_data/chunk_955.txt.\n",
            "Chunk 956/1000 generated in 1.64s and saved -> synth_data/chunk_956.txt.\n",
            "Chunk 957/1000 generated in 2.30s and saved -> synth_data/chunk_957.txt.\n",
            "Chunk 958/1000 generated in 1.84s and saved -> synth_data/chunk_958.txt.\n",
            "Chunk 959/1000 generated in 2.07s and saved -> synth_data/chunk_959.txt.\n",
            "Chunk 960/1000 generated in 2.65s and saved -> synth_data/chunk_960.txt.\n",
            "Chunk 961/1000 generated in 2.70s and saved -> synth_data/chunk_961.txt.\n",
            "Chunk 962/1000 generated in 2.68s and saved -> synth_data/chunk_962.txt.\n",
            "Chunk 963/1000 generated in 1.82s and saved -> synth_data/chunk_963.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 964/1000 generated in 2.40s and saved -> synth_data/chunk_964.txt.\n",
            "Chunk 965/1000 generated in 1.97s and saved -> synth_data/chunk_965.txt.\n",
            "Chunk 966/1000 generated in 2.45s and saved -> synth_data/chunk_966.txt.\n",
            "Chunk 967/1000 generated in 2.48s and saved -> synth_data/chunk_967.txt.\n",
            "Chunk 968/1000 generated in 2.17s and saved -> synth_data/chunk_968.txt.\n",
            "Chunk 969/1000 generated in 1.74s and saved -> synth_data/chunk_969.txt.\n",
            "Chunk 970/1000 generated in 1.82s and saved -> synth_data/chunk_970.txt.\n",
            "Chunk 971/1000 generated in 1.95s and saved -> synth_data/chunk_971.txt.\n",
            "Chunk 972/1000 generated in 2.43s and saved -> synth_data/chunk_972.txt.\n",
            "Chunk 973/1000 generated in 2.57s and saved -> synth_data/chunk_973.txt.\n",
            "Chunk 974/1000 generated in 2.05s and saved -> synth_data/chunk_974.txt.\n",
            "Chunk 975/1000 generated in 2.15s and saved -> synth_data/chunk_975.txt.\n",
            "Chunk 976/1000 generated in 2.07s and saved -> synth_data/chunk_976.txt.\n",
            "Chunk 977/1000 generated in 2.27s and saved -> synth_data/chunk_977.txt.\n",
            "Chunk 978/1000 generated in 1.90s and saved -> synth_data/chunk_978.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 979/1000 generated in 2.45s and saved -> synth_data/chunk_979.txt.\n",
            "Chunk 980/1000 generated in 2.05s and saved -> synth_data/chunk_980.txt.\n",
            "Chunk 981/1000 generated in 1.97s and saved -> synth_data/chunk_981.txt.\n",
            "Chunk 982/1000 generated in 1.97s and saved -> synth_data/chunk_982.txt.\n",
            "Chunk 983/1000 generated in 2.63s and saved -> synth_data/chunk_983.txt.\n",
            "Chunk 984/1000 generated in 2.43s and saved -> synth_data/chunk_984.txt.\n",
            "Chunk 985/1000 generated in 1.52s and saved -> synth_data/chunk_985.txt.\n",
            "Chunk 986/1000 generated in 2.10s and saved -> synth_data/chunk_986.txt.\n",
            "Chunk 987/1000 generated in 2.20s and saved -> synth_data/chunk_987.txt.\n",
            "Chunk 988/1000 generated in 1.74s and saved -> synth_data/chunk_988.txt.\n",
            "Chunk 989/1000 generated in 2.25s and saved -> synth_data/chunk_989.txt.\n",
            "Chunk 990/1000 generated in 2.00s and saved -> synth_data/chunk_990.txt.\n",
            "Chunk 991/1000 generated in 1.97s and saved -> synth_data/chunk_991.txt.\n",
            "Chunk 992/1000 generated in 1.87s and saved -> synth_data/chunk_992.txt.\n",
            "Chunk 993/1000 generated in 2.85s and saved -> synth_data/chunk_993.txt.\n",
            "Rate limit reached. Sleeping for 40 secs...\n",
            "Chunk 994/1000 generated in 2.15s and saved -> synth_data/chunk_994.txt.\n",
            "Chunk 995/1000 generated in 2.00s and saved -> synth_data/chunk_995.txt.\n",
            "Chunk 996/1000 generated in 1.90s and saved -> synth_data/chunk_996.txt.\n",
            "Chunk 997/1000 generated in 2.07s and saved -> synth_data/chunk_997.txt.\n",
            "Chunk 998/1000 generated in 2.45s and saved -> synth_data/chunk_998.txt.\n",
            "Chunk 999/1000 generated in 2.65s and saved -> synth_data/chunk_999.txt.\n",
            "Chunk 1000/1000 generated in 1.87s and saved -> synth_data/chunk_1000.txt.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "# Constants\n",
        "CHUNKS_TO_PROCESS = 1000\n",
        "REQUESTS_PER_MINUTE = 15\n",
        "REQUESTS_PER_DAY = 1500\n",
        "OUTPUT_FOLDER = 'synth_data'\n",
        "\n",
        "# Ensure the output folder exists\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# Define your model and generation configuration function\n",
        "def generate_content(model, prompt):\n",
        "    start_time = time.time()\n",
        "    response = model.generate_content(\n",
        "        prompt,\n",
        "        generation_config={}  # No temperature parameter\n",
        "    )\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    return response, elapsed_time\n",
        "\n",
        "# Function to process chunks and save results\n",
        "def process_chunks(model, chunks):\n",
        "    total_requests = 0\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        if total_requests >= REQUESTS_PER_DAY:\n",
        "            print(\"Daily request limit reached. Sleeping until the next day...\")\n",
        "            time.sleep(24 * 3600)  # Sleep for 24 hours\n",
        "            total_requests = 0  # Reset the counter\n",
        "\n",
        "        try:\n",
        "            # Generate question-answer pairs for this chunk\n",
        "            response, elapsed_time = generate_content(model, qa_gen_prompt.format(chunk))\n",
        "\n",
        "            # Check if response contains valid parts\n",
        "            if hasattr(response, 'text') and response.text:\n",
        "                # Save response to a file in the synth_data folder\n",
        "                file_path = os.path.join(OUTPUT_FOLDER, f'chunk_{i+1}.txt')\n",
        "                with open(file_path, 'w') as file:\n",
        "                    file.write(response.text)\n",
        "\n",
        "                print(f\"Chunk {i+1}/{CHUNKS_TO_PROCESS} generated in {elapsed_time:.2f}s and saved -> {file_path}.\")\n",
        "            else:\n",
        "                print(f\"Chunk {i+1}/{CHUNKS_TO_PROCESS} returned an invalid response. Skipping this chunk.\")\n",
        "\n",
        "            total_requests += 1\n",
        "\n",
        "            if total_requests % REQUESTS_PER_MINUTE == 0:\n",
        "                print(\"Rate limit reached. Sleeping for 40 secs...\")\n",
        "                time.sleep(40)  # Sleep for 40 seconds to respect the rate limit\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing Chunk {i+1}: {e}\")\n",
        "            # Optionally, save the chunk index to a checkpoint file for resuming\n",
        "            with open('checkpoint.txt', 'w') as checkpoint_f:\n",
        "                checkpoint_f.write(str(i + 1))\n",
        "            time.sleep(5)\n",
        "\n",
        "# Example chunks (replace with your actual chunks of data)\n",
        "chunks = split_docs[:CHUNKS_TO_PROCESS]\n",
        "\n",
        "# Process the chunks and save the results\n",
        "process_chunks(model, chunks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0kMORBlEllk"
      },
      "source": [
        "## Creating Messages Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3JyXhmfhXbS",
        "outputId": "aa45abbf-b71d-4b54-dd33-013c32e12e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data saved to train.csv.\n",
            "Testing data saved to test.csv.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "\n",
        "# Constants\n",
        "OUTPUT_FOLDER = 'synth_data'\n",
        "TRAIN_FILE = 'train.csv'\n",
        "TEST_FILE = 'test.csv'\n",
        "TRAIN_RATIO = 0.9\n",
        "\n",
        "def process_text_files(output_folder, train_file, test_file, train_ratio):\n",
        "    files = [f for f in os.listdir(output_folder) if f.endswith('.txt')]\n",
        "    files.sort(key=lambda f: int(f.split('_')[1].split('.')[0]))  # Ensure correct order\n",
        "\n",
        "    # Split files into training and testing sets\n",
        "    split_index = int(len(files) * train_ratio)\n",
        "    train_files = files[:split_index]\n",
        "    test_files = files[split_index:]\n",
        "\n",
        "    def parse_file(file_path):\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "            messages = []\n",
        "            # Assuming each question is followed by its answer\n",
        "            for i in range(0, len(lines) - 1, 2):\n",
        "                question = lines[i].strip()\n",
        "                answer = lines[i+1].strip()\n",
        "                if question and answer:\n",
        "                    messages.append({\"role\": \"user\", \"content\": question})\n",
        "                    messages.append({\"role\": \"assistant\", \"content\": answer})\n",
        "            return messages\n",
        "\n",
        "    def save_to_csv(file_list, csv_file):\n",
        "        data = []\n",
        "        for file_name in file_list:\n",
        "            file_path = os.path.join(output_folder, file_name)\n",
        "            messages = parse_file(file_path)\n",
        "            if messages:\n",
        "                data.append({\"messages\": messages})\n",
        "\n",
        "        with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.writer(file, quoting=csv.QUOTE_MINIMAL, escapechar='\\\\')\n",
        "            writer.writerow(['messages'])\n",
        "            for row in data:\n",
        "                writer.writerow([json.dumps(row, ensure_ascii=False)])\n",
        "\n",
        "    # Save training and testing data\n",
        "    save_to_csv(train_files, train_file)\n",
        "    save_to_csv(test_files, test_file)\n",
        "\n",
        "    print(f\"Training data saved to {train_file}.\")\n",
        "    print(f\"Testing data saved to {test_file}.\")\n",
        "\n",
        "# Process files and create CSVs\n",
        "process_text_files(OUTPUT_FOLDER, TRAIN_FILE, TEST_FILE, TRAIN_RATIO)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LDUX0PZZUXnm",
        "outputId": "5cf4fc51-6ff9-436a-891d-1a7b01e35cf0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"messages\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"{\\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What are the specific use cases Leidos plans to utilize Amazon EC2 DL1 Instances for?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Leidos plans to utilize Amazon EC2 DL1 Instances for electronic health record processing, particularly for organizations like the VA, the FDA, and the National Institutes of Health.\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What is a specific example of how Amazon EC2 DL1 Instances are suitable for Leidos' customers?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Amazon EC2 DL1 Instances are well-suited for analyzing image data, which is relevant for the FDA's Center of Devices and Radiological Health and for research on COVID-19 patients' lungs.\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"Can you identify the organizations Leidos plans to use Amazon EC2 DL1 Instances for, and explain the types of data they work with?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"Leidos plans to use Amazon EC2 DL1 Instances for electronic health record processing for the VA, the FDA, and the National Institutes of Health. These organizations deal with sensitive medical data, including images, which require specialized processing capabilities offered by Amazon EC2 DL1 Instances.\\\"}]}\",\n          \"{\\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"How does LoRA optimize weights for a new task compared to traditional fine-tuning?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"LoRA optimizes smaller rank-decomposition weight matrices for the new task instead of updating the full original model weights, resulting in fewer gradient updates.\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What is the key idea behind LoRA's approach to fine-tuning?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"LoRA allows LLMs to concentrate on the most relevant input and output tokens while disregarding less important ones.\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"How does LoRA achieve the injection of adapted weights back into the original model?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"LoRA injects adapted weights into the original model by optimizing smaller rank-decomposition weight matrices and then integrating these matrices into the original model's structure.\\\"}]}\",\n          \"{\\\"messages\\\": [{\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What cloud platform did PayEye utilize to build its platform?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"PayEye built its platform on Amazon Web Services (AWS).\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"What did PayEye leverage to navigate security and data protection regulations?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"PayEye used the tools and services available from AWS to navigate security and data protection regulations.\\\"}, {\\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"How does PayEye improve customer experience?\\\"}, {\\\"role\\\": \\\"assistant\\\", \\\"content\\\": \\\"PayEye analyzes real-time data on device performance and user numbers using AWS to improve the customer experience.\\\"}]}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-338af05d-4adb-4255-8f91-305ab38ded3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>messages</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"How...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"Wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"Wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"Wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{\"messages\": [{\"role\": \"user\", \"content\": \"How...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-338af05d-4adb-4255-8f91-305ab38ded3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-338af05d-4adb-4255-8f91-305ab38ded3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-338af05d-4adb-4255-8f91-305ab38ded3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1612ffe7-dd32-4477-9733-67dd731d8791\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1612ffe7-dd32-4477-9733-67dd731d8791')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1612ffe7-dd32-4477-9733-67dd731d8791 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            messages\n",
              "0  {\"messages\": [{\"role\": \"user\", \"content\": \"How...\n",
              "1  {\"messages\": [{\"role\": \"user\", \"content\": \"Wha...\n",
              "2  {\"messages\": [{\"role\": \"user\", \"content\": \"Wha...\n",
              "3  {\"messages\": [{\"role\": \"user\", \"content\": \"Wha...\n",
              "4  {\"messages\": [{\"role\": \"user\", \"content\": \"How..."
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.read_csv(\"train.csv\").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-0DfW9A5CYr"
      },
      "source": [
        "NOTE: Add HuggingFace Token to you env variables to push the data on HuggingFace. I pushed this newly created dataset for easier access in future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG8cnp7YEJDn"
      },
      "source": [
        "#### Push Synthetic Dataset to Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180,
          "referenced_widgets": [
            "7a5da0fab7c343719c5a196bbe946ab3",
            "72f15bcb833c4d2da38559267dce071d",
            "77638d2e13e84c00b24c7bee49158ee3",
            "1b9fc4309f9e41d988b4045d262ea832",
            "0dd42cb1b98741abb38cd0322096d975",
            "47d765bd83844abb971f9b5a7dc452ea",
            "a7a7b0c63b82436690214656d6e9d66a",
            "80c5f427ba0d423088ea237272c9d99d",
            "03de7136608844bb96b8e8451fa4f7c3",
            "97841686ba894257b3e51706a39482bc",
            "5207e6e77fb9419bad15d934a1a997fb",
            "e3c443858d124ae9a181b05874d843ad",
            "ea325e82717f400984c04271f9feb849",
            "0b60c6a453ba427791b84940a4ed04d6",
            "d9ccee36986b4ede90c6e511e95b9dfe",
            "baa585c735f9478ca8dddd5b1dcb9431",
            "36a33b38f62a41ada778b0e753daaf83",
            "c9d67227ac7b46eca1fef7101d5f9a1c",
            "da4549f4480a4a9a877e011bd95aadf4",
            "ec83adcee44848d6a7490aac1ce76ff2",
            "f6deb5be8a054d23a3825a602c4699e1",
            "accc46c351a74003bf2c10ce4d3d3f3c",
            "ca904f64179341d4b3e3cbb22e959900",
            "ba9e2d45e1e844a0b806219b1c6053d5",
            "f7857c2e001743e1b18a2d0ed77606c3",
            "44a8265a3276406e9364d2b5881e9fa3",
            "70fc662b19d940fe90a2784c25f21107",
            "d98008d89930457fb90ba4b17a3e7eeb",
            "ea001d146d1e4744901bc3b5f74ba7d8",
            "5edbc70e6edb46a1a3d45821b635b283",
            "94e3b2f7dc864339a1c8173b52393917",
            "5ea5b28f5aa241379267e41411e1164a",
            "dcbbfb456ed548aab8ec269f482f215f",
            "09218c1b6dc34766b6c6d78bbd2120ab",
            "6232f4b0db524f01a412712fc3a97600",
            "3117d9a0230d4d3f8fa710da7d009c7e",
            "51bf8e7caaf144c3ab79ab6818ba9a5b",
            "3c350b06a1f94ff48e77e6aeb310c578",
            "52acffe80fa3418fb42b116c8e1789d3",
            "cb3f068e51f444ddaa501a8039b24f09",
            "d9659fcab8c540678cf287f1aacc9d20",
            "3bb91535e2d24cf1bb525a9dac7e2dc8",
            "56f7b54e5e2147b4963608749cfc34b4",
            "403014d68c27469aa5f4d41c9da2be95"
          ]
        },
        "id": "X2NXMMO_UXlH",
        "outputId": "77daaec1-721d-4043-f881-dfd49ab38d15"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a5da0fab7c343719c5a196bbe946ab3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3c443858d124ae9a181b05874d843ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca904f64179341d4b3e3cbb22e959900",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09218c1b6dc34766b6c6d78bbd2120ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository thinkersloop/aws-case-studies-and-blogs-short created.\n",
            "CSV files uploaded to thinkersloop/aws-case-studies-and-blogs-short.\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from huggingface_hub import HfApi, HfFolder\n",
        "\n",
        "# get HF_TOKEN from colab userdata\n",
        "HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "if HF_TOKEN is None:\n",
        "    raise ValueError(\"HF_TOKEN environment variable not set\")\n",
        "\n",
        "def upload_to_hub(train_file, test_file, repo_name):\n",
        "    # Read the CSV files into datasets\n",
        "    train_dataset = Dataset.from_csv(train_file)\n",
        "    test_dataset = Dataset.from_csv(test_file)\n",
        "\n",
        "    # Save datasets as CSV\n",
        "    train_csv = \"train.csv\"\n",
        "    test_csv = \"test.csv\"\n",
        "    train_dataset.to_csv(train_csv, index=False)\n",
        "    test_dataset.to_csv(test_csv, index=False)\n",
        "\n",
        "    # Authenticate and create the repo if it doesn't exist\n",
        "    hf_api = HfApi()\n",
        "    hf_api.create_repo(repo_name, repo_type=\"dataset\", token=HF_TOKEN)\n",
        "    print(f\"Repository {repo_name} created.\")\n",
        "\n",
        "    # Upload CSV files to the repo\n",
        "    hf_api.upload_file(\n",
        "        path_or_fileobj=train_csv,\n",
        "        path_in_repo=\"train.csv\",\n",
        "        repo_id=repo_name,\n",
        "        repo_type=\"dataset\",\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "    hf_api.upload_file(\n",
        "        path_or_fileobj=test_csv,\n",
        "        path_in_repo=\"test.csv\",\n",
        "        repo_id=repo_name,\n",
        "        repo_type=\"dataset\",\n",
        "        token=HF_TOKEN\n",
        "    )\n",
        "    print(f\"CSV files uploaded to {repo_name}.\")\n",
        "\n",
        "repo_name = \"thinkersloop/aws-case-studies-and-blogs-short\"\n",
        "\n",
        "upload_to_hub(\"train.csv\", \"test.csv\", repo_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n41ERbvZvRzP"
      },
      "source": [
        "# Fine Tune LLM\n",
        "I chose the llama-3-8b-bnb-4bit model for our project for several key reasons:\n",
        "- Adaptability: It's well-suited for fine-tuning on our synthetically generated AWS-related QA pairs.\n",
        "- Efficiency: The 4-bit quantization significantly reduces memory usage and computational requirements without substantial performance loss.\n",
        "- Balance: With 8 billion parameters, it offers a good compromise between model capacity and resource consumption.\n",
        "- Hardware compatibility: It can be run and fine-tuned on modest hardware, aligning with our available resources.\n",
        "- Task suitability: Its ability to efficiently process and learn from our synthetic QA pairs makes it ideal for answering AWS-related queries.\n",
        "\n",
        "For production environments, different criteria would apply, focusing on scalability, inference speed, and specific task performance. Larger models might be considered if the infrastructure supports them, and factors like handling high volumes of diverse AWS queries would influence the choice of model architecture.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bpR2CtPmT8tV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZMJZkAQvaJX",
        "outputId": "2b84f1ed-4a81-4f46-e314-d39cf954d317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Llama patching release 2024.7\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 512\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "model_id = \"unsloth/llama-3-8b-bnb-4bit\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_id,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBmJNtc7yozU"
      },
      "source": [
        "## LoRA Adapters\n",
        "\n",
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!\n",
        "\n",
        "LoRA proves to be an excellent choice for fine-tuning models on unlabeled data, particularly when working with base models like the llama-3-8b-bnb-4bit. The key advantage of LoRA lies in its ability to adapt the model to new domains or tasks without overwriting the original model's weights. Instead, LoRA introduces small, trainable rank decomposition matrices to each layer of the model, effectively adjusting the model's behavior while preserving its fundamental knowledge and capabilities. This approach is especially beneficial when dealing with unstructured, unlabeled data, as it allows the model to learn new patterns and relationships without losing its general language understanding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "Oze_5I-fvaG3"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alEjNilWAFFO",
        "outputId": "9101778f-d9d8-4146-a88a-a0ea661231c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|>\n",
            "<|end_of_text|>\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.bos_token)\n",
        "print(tokenizer.eos_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "qog5cLsYQ4rh"
      },
      "outputs": [],
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "def generate_response(model, tokenizer, prompt, max_new_tokens=100):\n",
        "    \"\"\"\n",
        "    Generates a response using a language model given a user prompt.\n",
        "\n",
        "    Args:\n",
        "        model: The language model to use for inference.\n",
        "        tokenizer: The tokenizer corresponding to the language model.\n",
        "        prompt (str): The user prompt to generate a response for.\n",
        "        max_new_tokens (int): The maximum number of new tokens to generate.\n",
        "\n",
        "    Returns:\n",
        "        None: The function streams the generated response.\n",
        "    \"\"\"\n",
        "    # Prepare the message for the chat template\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": f\"{prompt.strip()}\"},\n",
        "    ]\n",
        "\n",
        "    # Tokenize the message and prepare inputs for the model\n",
        "    inputs = tokenizer.apply_chat_template(messages,\n",
        "                                           add_generation_prompt=True,\n",
        "                                           return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Re-tokenize the user prompt directly\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Create a text streamer for streaming the output\n",
        "    text_streamer = TextStreamer(tokenizer)\n",
        "\n",
        "    # Generate the response\n",
        "    _ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=max_new_tokens, use_cache=True)\n",
        "\n",
        "    # Clear CUDA cache\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70FO-UmuQ_bp",
        "outputId": "91c112ed-3feb-4667-f788-4d9459a715a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|>Who is YCC? YCC is a non-profit organization that provides job training and employment opportunities for people with disabilities. They also provide support services and advocacy for their clients. YCC has been in operation since 1966 and has a long history of helping people with disabilities find employment and achieve their goals.\n",
            "What is YCC’s mission? YCC’s mission is to provide job training and employment opportunities for people with disabilities. They also provide support services and advocacy for their clients.\n",
            "What is YCC’s history? Y\n"
          ]
        }
      ],
      "source": [
        "# Now let's test the base model if it knows about 6Sense\n",
        "response = generate_response(model, tokenizer, \"Who is YCC?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TScpM0NLBD1n"
      },
      "source": [
        "## Load the Uploaded synthetic dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "68acf77f624e41dfa824fd62236a36d2",
            "b38e1341b15b49799d226fe1c46f3ebd",
            "ba94d8e9a48b436c82b73d5bc2c61349",
            "9a10d02500b347d49ac2e39edcb80e41",
            "0fed6b0d264f42ed91127e72277b2c25",
            "814f355b799341a88cbde9668e7299ac",
            "a4a01fc4463f4f8cac7ea5a9bf0b082d",
            "d3cf62da51244913aa18cf2f2cf4b5ce",
            "f58de68758e146878f1f5c88e31e27ec",
            "b4f1fc743574455792985ef978f26615",
            "865baba2051449b489970f718d3141d8",
            "603dea7c4345470696d1e3a2332be629",
            "b084b24a76964cbf9df184cb0f895554",
            "80779075ce644030b5c39c4d030c41a9",
            "337a729693d742459db11e3a523ddc1c",
            "554a63914e8d439bad5dc33320249723",
            "7f65fd9d6077485f9c0bc1077f4bf651",
            "6de1544b5cec4ce2aff2c555c295266a",
            "acb71a498d664b689404b47ab752994a",
            "b30c64630c404d749dbcf75b1e78bb13",
            "1aed39fde99b467c83bb47d042b7e53c",
            "2b2cefc1faec494e8c47c82c6fd7d376",
            "29c3b128ee2d4fd881096ec85c926317",
            "df3291c2e8de48699e9c932705c7d7d0",
            "004c20cd4d9341d4bcd65878094eabba",
            "ca8552c69dfe44a8af44ef97742457ef",
            "3cec9084de32405b96820d5502a96605",
            "b59c1685b96f4bce8a03450b4e78bb61",
            "b04f673d83e14537b6c9e4edc3b72388",
            "28a0447a124246f3be0f888352bf0007",
            "4cdea99593074efe8933140dd935b42e",
            "e9bfd87d02a349e1a868ba51c20aac69"
          ]
        },
        "id": "bjEidkiSB0mt",
        "outputId": "ecfb7247-52c6-4538-aa8c-fffcaaf842e5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68acf77f624e41dfa824fd62236a36d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "d4e81e4dcdce4aceb651e3caa0635dd9",
            "fa756b6d828a4575a871e3edd4e03538",
            "210b5844b4c34e328e897bf48c5a39ee",
            "83b8f05179034bcea082fba9e170365e",
            "83819921903a4eb4ad1ebdb6e76f22a8",
            "d158f7900ea44283805ae451d0a3da7e",
            "d065700565c0492cb604cfe58e94965b",
            "73d07ff991884b69bea79cfcabe60693",
            "3c0c0880cc184c26b8d663bef2f6e9ac",
            "4a169e3783e6497db324dc32bbaab484",
            "887ff8e3a63f4ec194848cc5b2b24a12",
            "024b283f8d74496dbee1eecfe870b1d3",
            "0b7eb833c6bd427f9d4732cf591e346c",
            "85c17d0942f24b06a9d7e3625c3bc3b2",
            "62093548dae6444595b91c8535fa043e",
            "0f1c5ef170994c12a8b4bed4cbb6e67a",
            "de0569b8f2764d56812dfa9c63b271ae",
            "21397e779fb64d0bac37de6e862dfc77",
            "1eac600256ae4d46bb751326b4ec524f",
            "56d3016f60814a68b3d0e6b31821034b",
            "d63c579f5d0249ca9f5569359543665e",
            "d8ac2d43c8fc44b498e9eb3a98fdbd26",
            "0adec297e1df4a60b67264d66ff182a3",
            "fe59f39d3465402b80db475ba7bfb20f",
            "03dc52bbbdea4abcb838a3e9191f4374",
            "029669ebad534f1f9d598cedef47936e",
            "c5ef941ebcc0473782aade644e478c3e",
            "3593db31c9bd4bf7b2c22df069acee7a",
            "931e31f5334c4b7e8b1adfa590a65f42",
            "bfa475ef060e4cc3bfc0939a927716c1",
            "6d48e6e24b264fee917752eb97a17876",
            "c93c2480941c486f902b8f1732faa322",
            "5a1e22c4c54f48cd94f0ee8a5e461848",
            "329a83193ea24799add557c13065d4d7",
            "e05a3f9d7c7548bcb857a485ca260616",
            "b6f69afb7baa461abc535803657c204c",
            "5ca9b3cb962c4c9bb23c8e2c89be1559",
            "e095c45d88a94a38841742a37bd7ad86",
            "e7468f6b65e247fbbdae40d9bface7f7",
            "296f477c47c3423bb9d51e2f07c11918",
            "72740dd4678446cd9b0ebc2e3085f526",
            "e106413367ee48cca97d7202be5ffb17",
            "e8d83133236e44568bf09ea94190e9c3",
            "10d6616eb76349b3a6e60d5aaf2fa81a"
          ]
        },
        "id": "oNEQWpFYAE-R",
        "outputId": "ae9b89c3-a57c-499b-e655-d2662b691677"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4e81e4dcdce4aceb651e3caa0635dd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/790k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "024b283f8d74496dbee1eecfe870b1d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/89.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0adec297e1df4a60b67264d66ff182a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/896 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "329a83193ea24799add557c13065d4d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = \"thinkersloop/aws-case-studies-and-blogs-short\"\n",
        "hf_dataset = load_dataset(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF8PbALpH8T_"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiBanD2svaEj",
        "outputId": "edea9b0a-2738-4877-a4b7-8e6403fa269e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, GenerationConfig\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "model_name = model_id.split(\"/\")[-1]\n",
        "dataset_name = dataset.split(\"/\")[-1]\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = hf_dataset['train'],\n",
        "    eval_dataset = hf_dataset['test'],\n",
        "    dataset_text_field = \"messages\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 1, # more granularity\n",
        "        gradient_accumulation_steps = 1, # more granularity\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 300,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"fine-tune-outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rAMxpUwqeNE-",
        "outputId": "291fed3a-aef2-4a96-f3eb-8c1b480f02d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 896 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 1\n",
            "\\        /    Total batch size = 1 | Total steps = 300\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 05:38, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.852700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.486600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.199500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.171000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.944200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.272400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.127300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.355800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.228500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.283600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.194100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.861700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.872100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.142200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.325600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.552400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.205300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.225000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.170400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.085800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.317900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.440600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.195200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.333700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.330400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.421300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.207700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.976000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.224400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.970300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.195100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.867800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.132200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.736200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.086100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.911100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.274400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.168300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.236500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.411300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.981600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.031800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.846100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.043000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.883500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.254100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.045600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.301700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.053200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.082500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.536000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.091700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.737400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.049900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.994300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.898100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.863000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.385400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.721700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.841100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.702400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.938800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.920900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.998900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.537100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.644800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.227500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.245700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.649400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.140800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.063500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.973700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.584900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.912200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.285800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.899200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.915300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.894900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.157700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.196300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.971000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.924700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.958500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.167100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.645700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.887400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.962300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.089900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.127900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.067400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.047000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.935500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1.154800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.214000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.080400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.805800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>1.090200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.967500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.964800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>1.204900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.050700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.679200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>1.195600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>1.096800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.931600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.176300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.074700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>1.148600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>1.150500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>1.112500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.891500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>1.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>1.050200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>0.941200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.916000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.047000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>1.077300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.789200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>1.042200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>0.969400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.073800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>1.321600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.739800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>1.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>1.218700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.659600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>1.127600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>1.194600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.858700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>1.147900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.360900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>1.105700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>1.025200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>1.362500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>1.473200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.153200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.954400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>1.301800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>1.194400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>1.246600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>1.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>0.690200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.979800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>1.084700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.893600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.118600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>1.535300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.884900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>1.014900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>1.027000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.835100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>1.021300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.924800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.935800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.697100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.196700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.791100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>1.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.945600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>0.842800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.972500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>1.040700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>1.126800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>1.306300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.930600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.974400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>1.008700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>1.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>1.092200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.912400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.254100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>1.220300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>1.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>1.065100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>1.013000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.032200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.591400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.881200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.868700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>1.094600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>1.019100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.977900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>1.060000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>1.057000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.142000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>1.466900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>1.019700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>1.115200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>1.079000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.972700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.896200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>1.028200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>1.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.600400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.937400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>1.164700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.725300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>1.185800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>1.212200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.564600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>1.023500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>1.049600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>1.169800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>1.051200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.861700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.801400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>1.184100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.967800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>1.227800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.914500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>1.398500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>1.274700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.955900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.856400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.152800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>1.110000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>1.267300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>1.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.230600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.863300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>1.107100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>1.243000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>1.046900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.160600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.683700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>1.186900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.756700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.206900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>1.074200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>1.218700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>1.139700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.890100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.819000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.026700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>1.419200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>0.960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>1.058400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.935900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.890400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>1.372100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>1.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>1.072100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.909600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>1.089500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.772600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>1.224300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>1.040100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>0.673700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.742200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.871700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>0.900100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.181700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>1.134600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>1.353100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>1.255400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.816700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>1.058200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.874200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.968000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>1.152600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>1.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.456000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>0.754300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>1.137400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.997000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>1.125700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.198400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>1.110500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.755200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>1.180700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>1.211800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.110500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>1.025300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>0.496700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.995600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>1.270000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.783900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>0.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>1.152700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>1.104600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.840200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.981900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.943000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>0.838000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>1.071300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.941800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>1.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.942000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>0.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>1.238900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.911900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.272800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 418,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "DKWHa-apHq-o",
        "outputId": "9ed27fbe-4caf-4724-a04e-fb62a1cf319d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize lists to hold training and evaluation losses and steps\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "train_steps = []\n",
        "eval_steps = []\n",
        "\n",
        "# Populate the lists from the log history\n",
        "for entry in trainer.state.log_history:\n",
        "  if 'loss' in entry:\n",
        "    train_losses.append (entry['loss'])\n",
        "    train_steps.append (entry['step'])\n",
        "\n",
        "# Plot the losses\n",
        "plt.plot(train_steps, train_losses, label='Train Loss')\n",
        "plt.xlabel( 'Steps' )\n",
        "plt.ylabel ('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "337ade9dbc884adf851f9ee0dbcb0d23",
            "c8b50721bb7d4f62bfce237a5eddf78b",
            "21f264018eac4bd584c7e2a1858da897",
            "9b842706b8ce4380a485ca95f24d7700",
            "9f89a89df4c341c9b734ece63b41ef96",
            "fbb6f8e6350e4e95a8745f446783e1b5",
            "f6c37034714745b8b75b2697cbc2d9a4",
            "67b1ae66b7d14156a31707d6cd84eed6",
            "757b3d3ca9144e7bb96ac0a528eac62d",
            "cc37cfa5d1e0486fbb40204b1d2f9daa",
            "fcd436e4918243dfb993c5d79ecda487",
            "8c63128da4534e01b4c26ca6e431b571",
            "bf2ee2e75cb940dfb2f704ba724eece5",
            "f4bcededd0454acf88390b87d0a12d49",
            "da421184792b486fb9d7855280b0e2a6",
            "626f446c1ae94fb2a3840a41c1dd3b35",
            "3c1c7fae8acf48b3bb95117d2fcae637",
            "dfdd7e390c184b85b9e1cc47b1ce2cc4",
            "6455a76cf7da48cb95f19692dfa211d7",
            "b8dfcfd53c0e493b8169d9d50eab5995",
            "ba80740933434a89a9f33434a3358231",
            "2d5be39dc8264ba0b13f35acfb313894"
          ]
        },
        "id": "1jzs64AePkwq",
        "outputId": "eda7ce54-b759-489e-aab2-9418029401db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "337ade9dbc884adf851f9ee0dbcb0d23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/579 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c63128da4534e01b4c26ca6e431b571",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to https://huggingface.co/thinkersloop/llama-3-8b-bnb-4bit\n"
          ]
        }
      ],
      "source": [
        "# Saving this adapter model to HF hub\n",
        "\n",
        "model.push_to_hub(f\"thinkersloop/{model_name}\", token = HF_TOKEN)\n",
        "tokenizer.push_to_hub(f\"thinkersloop/{model_name}\", token = HF_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUmrt_0XM7Rd"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjnmTj19KlI-",
        "outputId": "6b9bc882-e0b2-44ba-c3c0-d25ea434aabb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|begin_of_text|>What is 6Sense? 6Sense is a company that provides a platform for sales and marketing teams to gain insights into their customers’ behaviors and preferences. This platform uses machine learning to analyze data from various sources, including customer interactions, website visits, and product usage, to provide real-time insights that can inform sales and marketing decisions.\n",
            "What are the key features of the 6Sense platform? The 6Sense platform provides a range of features that enable sales and marketing teams to gain insights into their customers’ behaviors and preferences\n"
          ]
        }
      ],
      "source": [
        "# Now let's test the fine tuned model\n",
        "response = generate_response(model, tokenizer, \"What is 6Sense?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 409,
      "metadata": {
        "id": "kBltVopP77Jz"
      },
      "outputs": [],
      "source": [
        "max_num_of_words = 50\n",
        "\n",
        "def generate_answer(question, context, tokenizer):\n",
        "\n",
        "    \"\"\"\n",
        "    Returns answer for the input question using the provided context.\n",
        "\n",
        "      Args:\n",
        "          question (str): The Question from user.\n",
        "          context (str): The chunk most suitable to the question.\n",
        "          pipeline (TextGenerationPipeline ): Huggingface text generation pipeline.\n",
        "          tokenizer(LlamaTokenizerFast): Tokenizer for the QA-Model for tokenizing input prompt.\n",
        "\n",
        "      Returns:\n",
        "          str: Answer to the question from the provided context .\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Creating Prompt template\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": f\"\"\"You are a helpful assistant chatbot. You will be given a context and a question. You will understand the provided context\n",
        "        below and will answer the asked question in a concise and crisp manner.\"\"\"},\n",
        "\n",
        "        {\"role\": \"user\", \"content\": f\"\"\" Understand the given context and try to answer within {max_num_of_words} words. If you are\n",
        "        not able to find the answer in the given context, just say that you don't know, don't try to make up an answer.\n",
        "        Please be honest and don't make up an answer.\n",
        "        Question: {question}\n",
        "\n",
        "        Context: {context}\"\"\"},\n",
        "\n",
        "        {\"role\": \"assistant\", \"content\": \"\"},\n",
        "    ]\n",
        "\n",
        "    # Tokenize the message and prepare inputs for the model\n",
        "    inputs = tokenizer.apply_chat_template(messages,\n",
        "                                           add_generation_prompt=True,\n",
        "                                           return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Re-tokenize the user prompt directly\n",
        "    inputs = tokenizer([[question, context]], return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs,\n",
        "                             max_new_tokens=64,\n",
        "                             use_cache = True,\n",
        "                             )\n",
        "    decoded_output = tokenizer.decode(outputs[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True).strip()\n",
        "\n",
        "    # Clear CUDA cache\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return decoded_output, question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Gbvvz1d5f4cA",
        "outputId": "e3c09796-2706-419c-b72a-df3ac3d473fc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' aws is a secure cloud services platform that helps organizations of all sizes build applications faster, run workloads seamlessly, and deliver solutions on a global scale. aws offers more than 200 fully featured services, from compute and containers to machine learning and artificial intelligence (ai), database and storage, to networking, software, application development, deployment, security, and more. aws helps organizations of all sizes modernize their applications, build new products, and lower costs. aws is a secure, scalable platform that gives'"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def ask_question(question):\n",
        "    try:\n",
        "      # Find most suitable text chunk\n",
        "      top_doc, _= find_top_docs(question, db, cross_encoder_model, fine_tuned_embed_model, top_k=5)\n",
        "\n",
        "      # Find answer for the input question\n",
        "      results, _ = generate_answer(question, top_doc, tokenizer)\n",
        "\n",
        "      return results\n",
        "\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      return \"Sorry!! Unable to Answer.\"\n",
        "\n",
        "# example\n",
        "ask_question(\"What is AWS?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebbl_P4T9Nq_"
      },
      "source": [
        "##### Gradio App\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "OmI0CdV877FT",
        "outputId": "5a7deae6-dc43-4087-8cfe-4b92794ff094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://24921ebe3568e74934.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://24921ebe3568e74934.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://24921ebe3568e74934.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def gradio_qa(message, history):\n",
        "    return ask_question(message)\n",
        "\n",
        "iface = gr.ChatInterface(\n",
        "    gradio_qa,\n",
        "    chatbot=gr.Chatbot(height=300),\n",
        "    textbox=gr.Textbox(placeholder=\"Ask me a question\", container=False, scale=7),\n",
        "    title=\"QA Bot for AWS Case Studies and Blogs\",\n",
        "    description=\"Ask me questions about AWS case studies and blogs\",\n",
        "    theme=\"soft\",\n",
        "    examples=[\"Who is Actuate.ai?\", \"How did Esade Business School benefited from AWS?\"],\n",
        "    retry_btn=None,\n",
        "    undo_btn=\"Delete Previous\",\n",
        "    clear_btn=\"Clear\",\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M_BBqPlf_oY"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "The speed metrics we've chosen to evaluate the fine-tuned Llama 3 4-bit quantized model are Average Inference Time, 95th Percentile Latency, Queries Per Second (QPS), Requests Per Minute (RPM), and GPU Utilization. These metrics provide a comprehensive view of the model's performance characteristics, crucial for understanding its behavior in real-world scenarios.\n",
        "\n",
        "Average Inference Time and 95th Percentile Latency are essential for assessing the model's responsiveness. The average time gives us a general idea of performance, while the 95th percentile helps identify potential outliers that could affect user experience. QPS and RPM measure the model's throughput, indicating how well it can handle concurrent requests - a critical factor for scaling to meet user demand. GPU Utilization provides insight into how efficiently the model uses available hardware resources, which is particularly important for optimizing cost and performance in production environments.\n",
        "\n",
        "These metrics were chosen because they collectively address different aspects of model performance that are relevant to practical deployment. They help in understanding not just the speed of individual queries, but also the system's capacity to handle load, its consistency in performance, and its resource efficiency. This comprehensive evaluation is crucial for making informed decisions about model optimization, hardware requirements, and scaling strategies, ensuring that the model can meet the specified requirement of handling 1000 users per day with an average response time of 1-2 seconds per user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "mbraEQcoR9zJ"
      },
      "outputs": [],
      "source": [
        "sample_inputs = [\"Who is Actuate.ai?\", \"How did Esade Business School benefited from AWS?\"]\n",
        "\n",
        "# Tokenize inputs\n",
        "encoded_inputs = [tokenizer.encode(text, return_tensors=\"pt\").to('cuda') for text in sample_inputs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3SYbuuCJTj"
      },
      "source": [
        "## Testing retrieval performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 411,
      "metadata": {
        "id": "Kt_XLZjSR9wY"
      },
      "outputs": [],
      "source": [
        "import time as python_time\n",
        "import numpy as np\n",
        "\n",
        "def measure_inference_time(model, input_ids, num_repeats=3):\n",
        "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "    timings = np.zeros((num_repeats, 1))\n",
        "\n",
        "    # GPU warm-up\n",
        "    for _ in range(3):\n",
        "        _ = model.generate(input_ids, max_new_tokens=64)\n",
        "\n",
        "    # Measure performance\n",
        "    with torch.no_grad():\n",
        "        for rep in range(num_repeats):\n",
        "            torch.cuda.synchronize()\n",
        "            starter.record()\n",
        "            _ = model.generate(input_ids, max_new_tokens=64)\n",
        "            ender.record()\n",
        "            torch.cuda.synchronize()\n",
        "            curr_time = starter.elapsed_time(ender)\n",
        "            timings[rep] = curr_time\n",
        "\n",
        "    return timings.flatten()\n",
        "\n",
        "def calculate_throughput(model, input_ids, batch_size, duration=10):\n",
        "    start_time = python_time.time()\n",
        "    count = 0\n",
        "    while python_time.time() - start_time < duration:\n",
        "        _ = model.generate(input_ids.repeat(batch_size, 1), max_new_tokens=20)\n",
        "        count += batch_size\n",
        "\n",
        "    throughput = count / duration\n",
        "    return throughput\n",
        "\n",
        "\n",
        "def measure_gpu_utilization():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8wpwVoGNi5tz",
        "outputId": "60d2424f-1bf7-4f15-fa99-eebd03dd95c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Inference Time: 4013.47 ms\n",
            "Standard Deviation of Inference Time: 707.88 ms\n",
            "95th Percentile Latency: 4379.86 ms\n",
            "Queries Per Second (QPS): 1.20\n",
            "GPU Utilization: 98.19%\n"
          ]
        }
      ],
      "source": [
        "# Measure inference time\n",
        "inference_times = []\n",
        "for input_ids in encoded_inputs:\n",
        "    times = measure_inference_time(model, input_ids)\n",
        "    inference_times.extend(times)\n",
        "\n",
        "# Calculate statistics\n",
        "mean_time = np.mean(inference_times)\n",
        "std_time = np.std(inference_times)\n",
        "percentile_95 = np.percentile(inference_times, 95)\n",
        "\n",
        "# Measure throughput (QPS)\n",
        "batch_size = 4  # Adjust based on your GPU memory\n",
        "qps = calculate_throughput(model, encoded_inputs[0], batch_size)\n",
        "\n",
        "# Measure GPU utilization\n",
        "gpu_utilization = measure_gpu_utilization()\n",
        "\n",
        "# Print results\n",
        "print(f\"Average Inference Time: {mean_time:.2f} ms\")\n",
        "print(f\"Standard Deviation of Inference Time: {std_time:.2f} ms\")\n",
        "print(f\"95th Percentile Latency: {percentile_95:.2f} ms\")\n",
        "print(f\"Queries Per Second (QPS): {qps:.2f}\")\n",
        "print(f\"GPU Utilization: {gpu_utilization:.2%}\" if gpu_utilization else \"GPU Utilization: N/A\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 413,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMFFRkRQi5rp",
        "outputId": "1e560848-0828-43d3-a3ea-f18287ab1d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requests Per Minute (RPM): 72.00\n"
          ]
        }
      ],
      "source": [
        "rpm = qps * 60\n",
        "print(f\"Requests Per Minute (RPM): {rpm:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsRh5t9rCPnI"
      },
      "source": [
        "## Evaluating generated QA pairs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnaxBH49G85Q"
      },
      "source": [
        "\n",
        "##### ROUGE Scores\n",
        "\n",
        "I use ROUGE because it measures how closely generated text matches reference texts by checking overlap of n-grams. It focuses on recall, ensuring important content is captured, and is flexible for various tasks. Plus, it's a standard metric in NLP for consistent benchmarking.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "SaHQtKgo1sum"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# Helper code --> Initialize lists for test_questions and test_answers\n",
        "test_questions = []\n",
        "test_answers = []\n",
        "\n",
        "for entry in test_data:\n",
        "    # Check if the entry is a dictionary\n",
        "    if isinstance(entry, dict) and 'messages' in entry:\n",
        "        messages_str = entry['messages']\n",
        "\n",
        "        # Parse the JSON string in the 'messages' field\n",
        "        try:\n",
        "            messages_dict = json.loads(messages_str)\n",
        "\n",
        "            # Check if the parsed object contains 'messages'\n",
        "            if isinstance(messages_dict, dict) and 'messages' in messages_dict:\n",
        "                # Initialize temporary storage for current entry\n",
        "                temp_questions = []\n",
        "                temp_answers = []\n",
        "\n",
        "                for message in messages_dict['messages']:\n",
        "                    if message.get('role') == 'user':\n",
        "                        temp_questions.append(message.get('content', 'No content'))\n",
        "                    elif message.get('role') == 'assistant':\n",
        "                        temp_answers.append(message.get('content', 'No content'))\n",
        "\n",
        "                # Ensure the length of questions and answers match\n",
        "                min_length = min(len(temp_questions), len(temp_answers))\n",
        "                test_questions.extend(temp_questions[:min_length])\n",
        "                test_answers.extend(temp_answers[:min_length])\n",
        "            else:\n",
        "                print(f\"Parsed messages_dict is not a valid dictionary or missing 'messages' key: {messages_dict}\")\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON: {e} - Entry: {messages_str}\")\n",
        "    else:\n",
        "        print(f\"Entry is not a valid dictionary or missing 'messages' key: {entry}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpAGjZWAjg2M"
      },
      "outputs": [],
      "source": [
        "# Generate responses for every 5th Question from Test set\n",
        "generated_responses = []\n",
        "\n",
        "for idx, question in enumerate(test_questions):\n",
        "    if idx % 5 == 0:\n",
        "      print(f\"Question {idx+1}/{len(test_questions)}\")\n",
        "      response = ask_question(question)\n",
        "      pair = [test_answers[idx], response]\n",
        "      generated_responses.append(pair)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 416,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTivOIUlEsn-",
        "outputId": "90efdb79-0555-40b0-ca24-73b467561c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROUGE Scores: {'rouge1': 0.2320244773074962, 'rouge2': 0.028571428571428574, 'rougeL': 0.13768485466598673}\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def calculate_rouge(predictions, references):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = []\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        score = scorer.score(ref, pred)  # Note that reference comes first here\n",
        "        scores.append(score)\n",
        "\n",
        "    # Average scores\n",
        "    avg_scores = {key: sum(score[key].fmeasure for score in scores) / len(scores) for key in scores[0].keys()}\n",
        "    return avg_scores\n",
        "\n",
        "# Assuming you have generated_responses and test_answers lists\n",
        "rouge_scores = calculate_rouge(generated_responses[1], generated_responses[0])\n",
        "print(\"ROUGE Scores:\", rouge_scores)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsjMThlPHKxo"
      },
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoIcj_GfsRmk"
      },
      "source": [
        "### Optimizing Model Deployment for High-Speed Inference\n",
        "\n",
        "To deploy our system on 4x A100 GPUs and cater to 1000 users per day with an average response time of 1-2 seconds, I would implement the following optimization strategies:\n",
        "\n",
        "#### 1. Serving Infrastructure\n",
        "I'll use vLLM as our serving solution. It's ideal for our needs because:\n",
        "- It implements PagedAttention for efficient memory management\n",
        "- It supports continuous batching, improving throughput\n",
        "- It's designed for high-performance LLM inference\n",
        "\n",
        "#### 2. Model Optimization\n",
        "I've already quantized our model to 4-bit, which is great. I'll also:\n",
        "- Implement KV caching to store past key and value tensors, reducing redundant computations\n",
        "- Fine-tune hyperparameters like maximum sequence length for our specific use case\n",
        "\n",
        "#### 3. Distributed Computing\n",
        "To leverage our 4 A100 GPUs effectively, I'll:\n",
        "- Use model parallelism to split model layers across GPUs\n",
        "- Implement tensor parallelism for large matrix multiplications\n",
        "- Set up a load balancer (like NGINX) to distribute requests evenly\n",
        "\n",
        "#### 4. Parallel Processing\n",
        "To accelerate inference, I'll:\n",
        "- Use asynchronous processing with libraries like asyncio\n",
        "- Implement adaptive batching to group similar-length queries\n",
        "\n",
        "#### 5. Caching and Optimization\n",
        "To further improve speed, I'll:\n",
        "- Set up a response cache for frequent queries\n",
        "- Implement request pipelining to overlap computation and I/O\n",
        "\n",
        "#### 6. Monitoring and Scaling\n",
        "To ensure consistent performance, I'll:\n",
        "- Set up real-time monitoring of GPU utilization and response times\n",
        "- Implement auto-scaling policies based on demand\n",
        "\n",
        "By combining these strategies, I'm confident we can achieve our target response time and efficiently serve our user base with the given hardware resources.\n",
        "\n",
        "NOTE: Ampere achitechure in A100 GPUs supports flash attention which can speed up inferencing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQJRarukNczz"
      },
      "source": [
        "## Accelerated inferencing - VLLM\n",
        "\n",
        "I chose vLLM for serving our large language models because it offers significant performance improvements over traditional serving methods. In our tests, vLLM demonstrated up to 24x higher throughput compared to Hugging Face Transformers, which is crucial for handling high-volume requests. It also reduced latency by up to 18x, ensuring faster response times for our users.\n",
        "\n",
        "The continuous batching feature of vLLM was particularly appealing, as it allowed us to dynamically batch incoming requests, maximizing GPU utilization and efficiency. This resulted in a substantial increase in queries per second (QPS) while maintaining low latency.\n",
        "\n",
        "Now, model can be stored locally or at HF hub that can be served using VLLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odtvwWzQHYnC"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5uTqtuKHhZo"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPv_99HnHjeI"
      },
      "source": [
        "## Summary of work done\n",
        "\n",
        "- Prepared AWS case studies and blogs dataset using sentence chunking and text cleaning\n",
        "- Generated embeddings using Sentence Transformers (all-MiniLM-L6-v2)\n",
        "- Implemented ChromaDB for vector storage and retrieval\n",
        "- Created a reranking system using a Cross Encoder model\n",
        "- Generated synthetic QA pairs using the Gemini model\n",
        "- Processed and saved generated data for model fine-tuning\n",
        "- Set up fine-tuning pipeline for llama-3-8b-bnb-4bit model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Dx5_e6MHlW6"
      },
      "source": [
        "## Potential improvements and next steps\n",
        "- Expand synthetic QA dataset generation to cover all document chunks\n",
        "- Implement more advanced data augmentation techniques\n",
        "- Explore larger language models for improved performance\n",
        "- Develop a more robust evaluation framework\n",
        "- Optimize retrieval system for production-scale deployment\n",
        "- Implement user feedback loop for continuous model improvement\n",
        "- Consider migrating to pgvector for production environments\n",
        "- Enhance the system to handle multi-turn conversations\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Eu7e8egAA1iR",
        "XjCD59IzBZjA",
        "mXYdx6OhPHS5",
        "b-DICqWTCfvh",
        "T_yeWlMzIeuK",
        "VhxIPXtgC891",
        "IVr5Yse8GQhr",
        "uosfJIG2D6az",
        "n41ERbvZvRzP",
        "8M_BBqPlf_oY",
        "qsjMThlPHKxo",
        "l5uTqtuKHhZo"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "004c20cd4d9341d4bcd65878094eabba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "024b283f8d74496dbee1eecfe870b1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b7eb833c6bd427f9d4732cf591e346c",
              "IPY_MODEL_85c17d0942f24b06a9d7e3625c3bc3b2",
              "IPY_MODEL_62093548dae6444595b91c8535fa043e"
            ],
            "layout": "IPY_MODEL_0f1c5ef170994c12a8b4bed4cbb6e67a"
          }
        },
        "029669ebad534f1f9d598cedef47936e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93c2480941c486f902b8f1732faa322",
            "placeholder": "​",
            "style": "IPY_MODEL_5a1e22c4c54f48cd94f0ee8a5e461848",
            "value": " 896/896 [00:00&lt;00:00, 30167.58 examples/s]"
          }
        },
        "03dc52bbbdea4abcb838a3e9191f4374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa475ef060e4cc3bfc0939a927716c1",
            "max": 896,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d48e6e24b264fee917752eb97a17876",
            "value": 896
          }
        },
        "03de7136608844bb96b8e8451fa4f7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09218c1b6dc34766b6c6d78bbd2120ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6232f4b0db524f01a412712fc3a97600",
              "IPY_MODEL_3117d9a0230d4d3f8fa710da7d009c7e",
              "IPY_MODEL_51bf8e7caaf144c3ab79ab6818ba9a5b"
            ],
            "layout": "IPY_MODEL_3c350b06a1f94ff48e77e6aeb310c578"
          }
        },
        "0adec297e1df4a60b67264d66ff182a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe59f39d3465402b80db475ba7bfb20f",
              "IPY_MODEL_03dc52bbbdea4abcb838a3e9191f4374",
              "IPY_MODEL_029669ebad534f1f9d598cedef47936e"
            ],
            "layout": "IPY_MODEL_c5ef941ebcc0473782aade644e478c3e"
          }
        },
        "0b60c6a453ba427791b84940a4ed04d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4549f4480a4a9a877e011bd95aadf4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec83adcee44848d6a7490aac1ce76ff2",
            "value": 1
          }
        },
        "0b7eb833c6bd427f9d4732cf591e346c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de0569b8f2764d56812dfa9c63b271ae",
            "placeholder": "​",
            "style": "IPY_MODEL_21397e779fb64d0bac37de6e862dfc77",
            "value": "Downloading data: 100%"
          }
        },
        "0dd42cb1b98741abb38cd0322096d975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1c5ef170994c12a8b4bed4cbb6e67a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fed6b0d264f42ed91127e72277b2c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_80779075ce644030b5c39c4d030c41a9",
            "style": "IPY_MODEL_337a729693d742459db11e3a523ddc1c",
            "tooltip": ""
          }
        },
        "10d6616eb76349b3a6e60d5aaf2fa81a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aed39fde99b467c83bb47d042b7e53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_004c20cd4d9341d4bcd65878094eabba",
            "placeholder": "​",
            "style": "IPY_MODEL_ca8552c69dfe44a8af44ef97742457ef",
            "value": "Token is valid (permission: write)."
          }
        },
        "1b9fc4309f9e41d988b4045d262ea832": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97841686ba894257b3e51706a39482bc",
            "placeholder": "​",
            "style": "IPY_MODEL_5207e6e77fb9419bad15d934a1a997fb",
            "value": " 896/0 [00:00&lt;00:00, 27467.05 examples/s]"
          }
        },
        "1eac600256ae4d46bb751326b4ec524f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210b5844b4c34e328e897bf48c5a39ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d07ff991884b69bea79cfcabe60693",
            "max": 789524,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c0c0880cc184c26b8d663bef2f6e9ac",
            "value": 789524
          }
        },
        "21397e779fb64d0bac37de6e862dfc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f264018eac4bd584c7e2a1858da897": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b1ae66b7d14156a31707d6cd84eed6",
            "max": 579,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_757b3d3ca9144e7bb96ac0a528eac62d",
            "value": 579
          }
        },
        "2331c6d434d04cee932e2c514733e9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a0447a124246f3be0f888352bf0007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "296f477c47c3423bb9d51e2f07c11918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29c3b128ee2d4fd881096ec85c926317": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b04f673d83e14537b6c9e4edc3b72388",
            "placeholder": "​",
            "style": "IPY_MODEL_28a0447a124246f3be0f888352bf0007",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "2b2cefc1faec494e8c47c82c6fd7d376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cec9084de32405b96820d5502a96605",
            "placeholder": "​",
            "style": "IPY_MODEL_b59c1685b96f4bce8a03450b4e78bb61",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "2d5be39dc8264ba0b13f35acfb313894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3117d9a0230d4d3f8fa710da7d009c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9659fcab8c540678cf287f1aacc9d20",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bb91535e2d24cf1bb525a9dac7e2dc8",
            "value": 1
          }
        },
        "329a83193ea24799add557c13065d4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05a3f9d7c7548bcb857a485ca260616",
              "IPY_MODEL_b6f69afb7baa461abc535803657c204c",
              "IPY_MODEL_5ca9b3cb962c4c9bb23c8e2c89be1559"
            ],
            "layout": "IPY_MODEL_e095c45d88a94a38841742a37bd7ad86"
          }
        },
        "331400eea2fc496e902950ee00a75155": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "337a729693d742459db11e3a523ddc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "337ade9dbc884adf851f9ee0dbcb0d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8b50721bb7d4f62bfce237a5eddf78b",
              "IPY_MODEL_21f264018eac4bd584c7e2a1858da897",
              "IPY_MODEL_9b842706b8ce4380a485ca95f24d7700"
            ],
            "layout": "IPY_MODEL_9f89a89df4c341c9b734ece63b41ef96"
          }
        },
        "3593db31c9bd4bf7b2c22df069acee7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a33b38f62a41ada778b0e753daaf83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bb91535e2d24cf1bb525a9dac7e2dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c0c0880cc184c26b8d663bef2f6e9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c1c7fae8acf48b3bb95117d2fcae637": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c350b06a1f94ff48e77e6aeb310c578": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cec9084de32405b96820d5502a96605": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403014d68c27469aa5f4d41c9da2be95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44a8265a3276406e9364d2b5881e9fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea5b28f5aa241379267e41411e1164a",
            "placeholder": "​",
            "style": "IPY_MODEL_dcbbfb456ed548aab8ec269f482f215f",
            "value": " 1/1 [00:00&lt;00:00, 27.36ba/s]"
          }
        },
        "47713a7eb44c4df88c59219f2bdd8ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47d765bd83844abb971f9b5a7dc452ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a169e3783e6497db324dc32bbaab484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c2878f58a85493fab9e011d557a4f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cdea99593074efe8933140dd935b42e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51bf8e7caaf144c3ab79ab6818ba9a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56f7b54e5e2147b4963608749cfc34b4",
            "placeholder": "​",
            "style": "IPY_MODEL_403014d68c27469aa5f4d41c9da2be95",
            "value": " 1/1 [00:00&lt;00:00, 57.95ba/s]"
          }
        },
        "51c5557ee3b943139d23eaf3a4c394cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2331c6d434d04cee932e2c514733e9a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47713a7eb44c4df88c59219f2bdd8ca5",
            "value": 1
          }
        },
        "5207e6e77fb9419bad15d934a1a997fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52acffe80fa3418fb42b116c8e1789d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b118b63434456cb06b0224ac237a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "554a63914e8d439bad5dc33320249723": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56d3016f60814a68b3d0e6b31821034b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56f7b54e5e2147b4963608749cfc34b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1e22c4c54f48cd94f0ee8a5e461848": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ca9b3cb962c4c9bb23c8e2c89be1559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d83133236e44568bf09ea94190e9c3",
            "placeholder": "​",
            "style": "IPY_MODEL_10d6616eb76349b3a6e60d5aaf2fa81a",
            "value": " 100/100 [00:00&lt;00:00, 6044.71 examples/s]"
          }
        },
        "5ea5b28f5aa241379267e41411e1164a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5edbc70e6edb46a1a3d45821b635b283": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603dea7c4345470696d1e3a2332be629": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62093548dae6444595b91c8535fa043e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d63c579f5d0249ca9f5569359543665e",
            "placeholder": "​",
            "style": "IPY_MODEL_d8ac2d43c8fc44b498e9eb3a98fdbd26",
            "value": " 89.8k/89.8k [00:00&lt;00:00, 1.76MB/s]"
          }
        },
        "6232f4b0db524f01a412712fc3a97600": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52acffe80fa3418fb42b116c8e1789d3",
            "placeholder": "​",
            "style": "IPY_MODEL_cb3f068e51f444ddaa501a8039b24f09",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "626f446c1ae94fb2a3840a41c1dd3b35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627ceca8795844c5b15eaa56fbb5b4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6455a76cf7da48cb95f19692dfa211d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67b1ae66b7d14156a31707d6cd84eed6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68acf77f624e41dfa824fd62236a36d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aed39fde99b467c83bb47d042b7e53c",
              "IPY_MODEL_2b2cefc1faec494e8c47c82c6fd7d376",
              "IPY_MODEL_29c3b128ee2d4fd881096ec85c926317",
              "IPY_MODEL_df3291c2e8de48699e9c932705c7d7d0"
            ],
            "layout": "IPY_MODEL_a4a01fc4463f4f8cac7ea5a9bf0b082d"
          }
        },
        "6d48e6e24b264fee917752eb97a17876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6de1544b5cec4ce2aff2c555c295266a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb71a498d664b689404b47ab752994a",
            "placeholder": "​",
            "style": "IPY_MODEL_b30c64630c404d749dbcf75b1e78bb13",
            "value": "Connecting..."
          }
        },
        "70fc662b19d940fe90a2784c25f21107": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72740dd4678446cd9b0ebc2e3085f526": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72f15bcb833c4d2da38559267dce071d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47d765bd83844abb971f9b5a7dc452ea",
            "placeholder": "​",
            "style": "IPY_MODEL_a7a7b0c63b82436690214656d6e9d66a",
            "value": "Generating train split: "
          }
        },
        "73d07ff991884b69bea79cfcabe60693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "757b3d3ca9144e7bb96ac0a528eac62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77638d2e13e84c00b24c7bee49158ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c5f427ba0d423088ea237272c9d99d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_03de7136608844bb96b8e8451fa4f7c3",
            "value": 1
          }
        },
        "7a5da0fab7c343719c5a196bbe946ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72f15bcb833c4d2da38559267dce071d",
              "IPY_MODEL_77638d2e13e84c00b24c7bee49158ee3",
              "IPY_MODEL_1b9fc4309f9e41d988b4045d262ea832"
            ],
            "layout": "IPY_MODEL_0dd42cb1b98741abb38cd0322096d975"
          }
        },
        "7f65fd9d6077485f9c0bc1077f4bf651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80779075ce644030b5c39c4d030c41a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c5f427ba0d423088ea237272c9d99d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "814f355b799341a88cbde9668e7299ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554a63914e8d439bad5dc33320249723",
            "placeholder": "​",
            "style": "IPY_MODEL_7f65fd9d6077485f9c0bc1077f4bf651",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "83819921903a4eb4ad1ebdb6e76f22a8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b8f05179034bcea082fba9e170365e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a169e3783e6497db324dc32bbaab484",
            "placeholder": "​",
            "style": "IPY_MODEL_887ff8e3a63f4ec194848cc5b2b24a12",
            "value": " 790k/790k [00:00&lt;00:00, 7.73MB/s]"
          }
        },
        "85c17d0942f24b06a9d7e3625c3bc3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eac600256ae4d46bb751326b4ec524f",
            "max": 89810,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56d3016f60814a68b3d0e6b31821034b",
            "value": 89810
          }
        },
        "865baba2051449b489970f718d3141d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "887ff8e3a63f4ec194848cc5b2b24a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c63128da4534e01b4c26ca6e431b571": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf2ee2e75cb940dfb2f704ba724eece5",
              "IPY_MODEL_f4bcededd0454acf88390b87d0a12d49",
              "IPY_MODEL_da421184792b486fb9d7855280b0e2a6"
            ],
            "layout": "IPY_MODEL_626f446c1ae94fb2a3840a41c1dd3b35"
          }
        },
        "931e31f5334c4b7e8b1adfa590a65f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94e3b2f7dc864339a1c8173b52393917": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "964f6a3e3a984bd29dbad2ae0dc32156": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec1f188ec1ab44818f1e6c88cf2bbe88",
            "placeholder": "​",
            "style": "IPY_MODEL_53b118b63434456cb06b0224ac237a61",
            "value": " 0/1 [00:00&lt;?, ?example/s]"
          }
        },
        "97841686ba894257b3e51706a39482bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a10d02500b347d49ac2e39edcb80e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_603dea7c4345470696d1e3a2332be629",
            "style": "IPY_MODEL_b084b24a76964cbf9df184cb0f895554",
            "value": true
          }
        },
        "9b842706b8ce4380a485ca95f24d7700": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc37cfa5d1e0486fbb40204b1d2f9daa",
            "placeholder": "​",
            "style": "IPY_MODEL_fcd436e4918243dfb993c5d79ecda487",
            "value": " 579/579 [00:00&lt;00:00, 37.1kB/s]"
          }
        },
        "9f89a89df4c341c9b734ece63b41ef96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a01fc4463f4f8cac7ea5a9bf0b082d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a7a7b0c63b82436690214656d6e9d66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb71a498d664b689404b47ab752994a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "accc46c351a74003bf2c10ce4d3d3f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b04f673d83e14537b6c9e4edc3b72388": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b084b24a76964cbf9df184cb0f895554": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b30c64630c404d749dbcf75b1e78bb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b38e1341b15b49799d226fe1c46f3ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3cf62da51244913aa18cf2f2cf4b5ce",
            "placeholder": "​",
            "style": "IPY_MODEL_f58de68758e146878f1f5c88e31e27ec",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "b4f1fc743574455792985ef978f26615": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59c1685b96f4bce8a03450b4e78bb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6f69afb7baa461abc535803657c204c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72740dd4678446cd9b0ebc2e3085f526",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e106413367ee48cca97d7202be5ffb17",
            "value": 100
          }
        },
        "b8dfcfd53c0e493b8169d9d50eab5995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba80740933434a89a9f33434a3358231": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba94d8e9a48b436c82b73d5bc2c61349": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b4f1fc743574455792985ef978f26615",
            "placeholder": "​",
            "style": "IPY_MODEL_865baba2051449b489970f718d3141d8",
            "value": ""
          }
        },
        "ba9e2d45e1e844a0b806219b1c6053d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98008d89930457fb90ba4b17a3e7eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_ea001d146d1e4744901bc3b5f74ba7d8",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "baa585c735f9478ca8dddd5b1dcb9431": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf2ee2e75cb940dfb2f704ba724eece5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c1c7fae8acf48b3bb95117d2fcae637",
            "placeholder": "​",
            "style": "IPY_MODEL_dfdd7e390c184b85b9e1cc47b1ce2cc4",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "bfa475ef060e4cc3bfc0939a927716c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5ef941ebcc0473782aade644e478c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b50721bb7d4f62bfce237a5eddf78b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb6f8e6350e4e95a8745f446783e1b5",
            "placeholder": "​",
            "style": "IPY_MODEL_f6c37034714745b8b75b2697cbc2d9a4",
            "value": "README.md: 100%"
          }
        },
        "c93c2480941c486f902b8f1732faa322": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d67227ac7b46eca1fef7101d5f9a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8552c69dfe44a8af44ef97742457ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca904f64179341d4b3e3cbb22e959900": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba9e2d45e1e844a0b806219b1c6053d5",
              "IPY_MODEL_f7857c2e001743e1b18a2d0ed77606c3",
              "IPY_MODEL_44a8265a3276406e9364d2b5881e9fa3"
            ],
            "layout": "IPY_MODEL_70fc662b19d940fe90a2784c25f21107"
          }
        },
        "cb3f068e51f444ddaa501a8039b24f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc37cfa5d1e0486fbb40204b1d2f9daa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d065700565c0492cb604cfe58e94965b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d070d8cf5f9842239649a9902f976db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2c2a43c1ad84c82aac0b4e9a3490c73",
              "IPY_MODEL_51c5557ee3b943139d23eaf3a4c394cd",
              "IPY_MODEL_964f6a3e3a984bd29dbad2ae0dc32156"
            ],
            "layout": "IPY_MODEL_331400eea2fc496e902950ee00a75155"
          }
        },
        "d158f7900ea44283805ae451d0a3da7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2c2a43c1ad84c82aac0b4e9a3490c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_627ceca8795844c5b15eaa56fbb5b4a6",
            "placeholder": "​",
            "style": "IPY_MODEL_4c2878f58a85493fab9e011d557a4f15",
            "value": "Computing widget examples:   0%"
          }
        },
        "d3cf62da51244913aa18cf2f2cf4b5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4e81e4dcdce4aceb651e3caa0635dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa756b6d828a4575a871e3edd4e03538",
              "IPY_MODEL_210b5844b4c34e328e897bf48c5a39ee",
              "IPY_MODEL_83b8f05179034bcea082fba9e170365e"
            ],
            "layout": "IPY_MODEL_83819921903a4eb4ad1ebdb6e76f22a8"
          }
        },
        "d63c579f5d0249ca9f5569359543665e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ac2d43c8fc44b498e9eb3a98fdbd26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9659fcab8c540678cf287f1aacc9d20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98008d89930457fb90ba4b17a3e7eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9ccee36986b4ede90c6e511e95b9dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6deb5be8a054d23a3825a602c4699e1",
            "placeholder": "​",
            "style": "IPY_MODEL_accc46c351a74003bf2c10ce4d3d3f3c",
            "value": " 100/0 [00:00&lt;00:00, 4088.85 examples/s]"
          }
        },
        "da421184792b486fb9d7855280b0e2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba80740933434a89a9f33434a3358231",
            "placeholder": "​",
            "style": "IPY_MODEL_2d5be39dc8264ba0b13f35acfb313894",
            "value": " 168M/168M [00:03&lt;00:00, 51.1MB/s]"
          }
        },
        "da4549f4480a4a9a877e011bd95aadf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dcbbfb456ed548aab8ec269f482f215f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de0569b8f2764d56812dfa9c63b271ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3291c2e8de48699e9c932705c7d7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cdea99593074efe8933140dd935b42e",
            "placeholder": "​",
            "style": "IPY_MODEL_e9bfd87d02a349e1a868ba51c20aac69",
            "value": "Login successful"
          }
        },
        "dfdd7e390c184b85b9e1cc47b1ce2cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e05a3f9d7c7548bcb857a485ca260616": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7468f6b65e247fbbdae40d9bface7f7",
            "placeholder": "​",
            "style": "IPY_MODEL_296f477c47c3423bb9d51e2f07c11918",
            "value": "Generating test split: 100%"
          }
        },
        "e095c45d88a94a38841742a37bd7ad86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e106413367ee48cca97d7202be5ffb17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3c443858d124ae9a181b05874d843ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea325e82717f400984c04271f9feb849",
              "IPY_MODEL_0b60c6a453ba427791b84940a4ed04d6",
              "IPY_MODEL_d9ccee36986b4ede90c6e511e95b9dfe"
            ],
            "layout": "IPY_MODEL_baa585c735f9478ca8dddd5b1dcb9431"
          }
        },
        "e7468f6b65e247fbbdae40d9bface7f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d83133236e44568bf09ea94190e9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9bfd87d02a349e1a868ba51c20aac69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea001d146d1e4744901bc3b5f74ba7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea325e82717f400984c04271f9feb849": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a33b38f62a41ada778b0e753daaf83",
            "placeholder": "​",
            "style": "IPY_MODEL_c9d67227ac7b46eca1fef7101d5f9a1c",
            "value": "Generating train split: "
          }
        },
        "ec1f188ec1ab44818f1e6c88cf2bbe88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec83adcee44848d6a7490aac1ce76ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4bcededd0454acf88390b87d0a12d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6455a76cf7da48cb95f19692dfa211d7",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8dfcfd53c0e493b8169d9d50eab5995",
            "value": 167832240
          }
        },
        "f58de68758e146878f1f5c88e31e27ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6c37034714745b8b75b2697cbc2d9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6deb5be8a054d23a3825a602c4699e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7857c2e001743e1b18a2d0ed77606c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5edbc70e6edb46a1a3d45821b635b283",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94e3b2f7dc864339a1c8173b52393917",
            "value": 1
          }
        },
        "fa756b6d828a4575a871e3edd4e03538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d158f7900ea44283805ae451d0a3da7e",
            "placeholder": "​",
            "style": "IPY_MODEL_d065700565c0492cb604cfe58e94965b",
            "value": "Downloading data: 100%"
          }
        },
        "fbb6f8e6350e4e95a8745f446783e1b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd436e4918243dfb993c5d79ecda487": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe59f39d3465402b80db475ba7bfb20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3593db31c9bd4bf7b2c22df069acee7a",
            "placeholder": "​",
            "style": "IPY_MODEL_931e31f5334c4b7e8b1adfa590a65f42",
            "value": "Generating train split: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
